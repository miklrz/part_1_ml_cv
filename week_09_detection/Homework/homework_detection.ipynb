{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8a7f379a-833c-4cfe-8860-3653c6fb0783",
      "metadata": {
        "id": "8a7f379a-833c-4cfe-8860-3653c6fb0783"
      },
      "source": [
        "<h3 style=\"text-align: center;\"><b>Школа глубокого обучения ФПМИ МФТИ</b></h3>\n",
        "\n",
        "<h3 style=\"text-align: center;\"><b>Домашнее задание. Детекция объектов</b></h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "149f6062-7f0c-42b9-ae36-0f360c852d25",
      "metadata": {
        "id": "149f6062-7f0c-42b9-ae36-0f360c852d25"
      },
      "source": [
        "В этом домашнем задании мы продолжим работу над детектором из семинара, поэтому при необходимости можете заимствовать оттуда любой код.\n",
        "\n",
        "Домашнее задание можно разделить на следующие части:\n",
        "\n",
        "* Переделываем модель [5]\n",
        "  * backbone[1],\n",
        "  * Neck [3],\n",
        "  * Head [1]\n",
        "* Label assignment [2]:\n",
        "  * TAL [2]\n",
        "* Лоссы [1]:\n",
        "  * CIoU loss [1]\n",
        "* Кто больше? [5]\n",
        "  * 0.15 mAP [1]\n",
        "  * 0.3 mAP  [2]\n",
        "  * 0.6 mAP [5]\n",
        "\n",
        "**Максимальный балл:** 10 баллов. (+3 балла бонус)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fb023c6-434e-47b4-b048-73683a6ce482",
      "metadata": {
        "id": "6fb023c6-434e-47b4-b048-73683a6ce482"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import albumentations as A\n",
        "\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset\n",
        "from albumentations.pytorch.transforms import ToTensorV2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42e2b5b2-113e-43d5-a134-31b51a256671",
      "metadata": {
        "id": "42e2b5b2-113e-43d5-a134-31b51a256671"
      },
      "source": [
        "### Загрузка данных\n",
        "\n",
        "Мы продолжаем работу с датасетом из семинара - Halo infinite ([сслыка](https://universe.roboflow.com/graham-doerksen/halo-infinite-angel-aim)). Загрузка данных и создание датасета полностью скопированы из семинара.\n",
        "\n",
        "Сначала загружаем данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2eecb64-16a2-4b97-b627-890ea316a594",
      "metadata": {
        "id": "b2eecb64-16a2-4b97-b627-890ea316a594"
      },
      "outputs": [],
      "source": [
        "splits = {'train': 'data/train-00000-of-00001-0d6632d599c29801.parquet',\n",
        "          'validation': 'data/validation-00000-of-00001-c6b77a557eeedd52.parquet',\n",
        "          'test': 'data/test-00000-of-00001-866d29d8989ea915.parquet'}\n",
        "df_train = pd.read_parquet(\"hf://datasets/Francesco/halo-infinite-angel-videogame/\" + splits[\"train\"])\n",
        "df_test = pd.read_parquet(\"hf://datasets/Francesco/halo-infinite-angel-videogame/\" + splits[\"test\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ade755e-4471-4c79-84bc-8b560484e833",
      "metadata": {
        "id": "1ade755e-4471-4c79-84bc-8b560484e833"
      },
      "source": [
        "Создаем датасет для предобработки данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a2f8ba9-5ae2-4d33-9d9d-5a0f0bb36d38",
      "metadata": {
        "id": "5a2f8ba9-5ae2-4d33-9d9d-5a0f0bb36d38"
      },
      "outputs": [],
      "source": [
        "class HaloDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        df_objects = pd.json_normalize(dataframe['objects'])[[\"bbox\", \"category\"]]\n",
        "        df_images = pd.json_normalize(dataframe['image'])[[\"bytes\"]]\n",
        "        self.data = dataframe[[\"image_id\"]].join(df_objects).join(df_images)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Загружаем данные и разметку для объекта с индексом `idx`.\n",
        "\n",
        "        labels: List[int] Набор классов для каждого ббокса,\n",
        "        boxes: List[List[int]] Набор ббоксов в формате (x_min, y_min, w, h).\n",
        "        \"\"\"\n",
        "        row = self.data.iloc[idx]\n",
        "        image = Image.open(io.BytesIO(row[\"bytes\"]))\n",
        "        image = np.array(image)\n",
        "\n",
        "        target = {}\n",
        "        target[\"image_id\"] = row[\"image_id\"]\n",
        "\n",
        "        labels = [row[\"category\"]] if isinstance(row[\"category\"], int) else row['category']\n",
        "        # Вычитаем единицу чтобы классы начинались с нуля\n",
        "        labels = [label - 1 for label in labels]\n",
        "        boxes = row['bbox'].tolist()\n",
        "\n",
        "        if self.transform is not None:\n",
        "            transformed = self.transform(image=image, bboxes=boxes, labels=labels)\n",
        "            image, boxes, labels = transformed[\"image\"], transformed[\"bboxes\"], transformed[\"labels\"]\n",
        "        else:\n",
        "            image = transforms.ToTensor()(image)\n",
        "\n",
        "        target['boxes'] = torch.tensor(np.array(boxes), dtype=torch.float32)\n",
        "        target['labels'] = torch.tensor(labels, dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch = tuple(zip(*batch))\n",
        "    images = torch.stack(batch[0])\n",
        "    return images, batch[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e864d642-45eb-4733-a763-2b2b7c711929",
      "metadata": {
        "id": "e864d642-45eb-4733-a763-2b2b7c711929"
      },
      "source": [
        "Тут можно написать любые аугментации"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c8c7095-9b77-4716-86cd-9b3e7dc3890c",
      "metadata": {
        "id": "9c8c7095-9b77-4716-86cd-9b3e7dc3890c"
      },
      "outputs": [],
      "source": [
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.229, 0.224, 0.225)\n",
        "\n",
        "train_transform = A.Compose(\n",
        "    [\n",
        "        # Добавляй сюда свои аугментации при необходимости!\n",
        "        A.Normalize(mean=mean, std=std),\n",
        "        ToTensorV2(),\n",
        "    ],\n",
        "    # Раскомментируй, если аугментации изменяют ббоксы.\n",
        "    # Не забудь указать верный формат для ббоксов.\n",
        "    # bbox_params=A.BboxParams(format='coco', label_fields=['labels'])\n",
        ")\n",
        "\n",
        "test_transform = A.Compose(\n",
        "    [\n",
        "        A.Normalize(mean=mean, std=std),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02c6edb2-f020-413c-8bf5-6b149e0086b6",
      "metadata": {
        "id": "02c6edb2-f020-413c-8bf5-6b149e0086b6"
      },
      "source": [
        "Не забываем инициализировать наш датасет"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4a10a88-6df0-4d1a-8640-eaca2f12e511",
      "metadata": {
        "id": "e4a10a88-6df0-4d1a-8640-eaca2f12e511"
      },
      "outputs": [],
      "source": [
        "train_dataset = HaloDataset(df_train, transform=train_transform)\n",
        "test_dataset = HaloDataset(df_test, transform=test_transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adb463da-ab51-460c-bfb9-e95dddfff90f",
      "metadata": {
        "id": "adb463da-ab51-460c-bfb9-e95dddfff90f"
      },
      "source": [
        "## Переделываем модель [5 баллов]\n",
        "\n",
        "В семинаре мы реализовали самый базовый детектор, а сейчас настало время его улучшать.\n",
        "\n",
        "### Backbone [1 балл]\n",
        "\n",
        "В лекции мы заморозили все слои у модели. Вам нужно написать бекбоун с возможностью разморозки __k__ последних слоев или блоков (на ваш выбор)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d92b9c64-73f8-4195-aa56-b9108589a312",
      "metadata": {
        "id": "d92b9c64-73f8-4195-aa56-b9108589a312"
      },
      "outputs": [],
      "source": [
        "class Backbone(nn.Module):\n",
        "    def __init__(self, ..., unfreeze_last=k):\n",
        "        # YOUR CODE HERE!\n",
        "\n",
        "    def forward(self, x):\n",
        "        # YOUR CODE HERE!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b3a3748-aa11-4bf8-9b38-59ff08366573",
      "metadata": {
        "id": "3b3a3748-aa11-4bf8-9b38-59ff08366573"
      },
      "source": [
        "### NECK [3 балла]\n",
        "\n",
        "Вам предлагается на выбор написать одну из двух шей:\n",
        "\n",
        "#### Feature Pyramid Network [2 балла]\n",
        "\n",
        "Знакомая из лекции архитектура шеи:\n",
        "\n",
        "<center><img src=\"https://user-images.githubusercontent.com/57972646/69858594-b14a6c00-12d5-11ea-8c3e-3c17063110d3.png\"/></center>\n",
        "\n",
        "\n",
        "* [Feature Pyramid Networks for Object Detection](https://arxiv.org/abs/1612.03144)\n",
        "\n",
        "Она состоит из top-down пути, в котором происходит 2 вещи:\n",
        "1. Увеличивается пространственная размерность фичей,\n",
        "2. С помощью скипконнекшеннов, добавляются фичи из backbone модели.\n",
        "\n",
        "Для увеличения пространственной размерности используется __nearest neighbor upsampling__, а фичи из шеи и бекбоуна суммируются.\n",
        "\n",
        "#### Path Aggregation Network [3 балла]\n",
        "\n",
        "Другая архитектура немного сложнее. Она содержит не только top-down путь, но ещё bottom-up путь:\n",
        "\n",
        "<center><img src=\"https://i.ibb.co/k68BWBGv/path-aggregation-network.png\" width=\"500\"/></center>\n",
        "\n",
        "* [Path Aggregation Network for Instance Segmentation](https://arxiv.org/abs/1803.01534)\n",
        "\n",
        "Подробное описание архитектуры можно найти в секции 3 (Framework). Реализовывать adaptive feature pooling не нужно.\n",
        "\n",
        "\n",
        "__TIPS__:\n",
        "* Можете использовать базовые классы из лекции,\n",
        "* Воспользуйтесь AnchorGenerator-ом, чтобы создавать якоря сразу для нескольких выходов,\n",
        "* Не забудьте использовать nn.ModuleList, если захотите сделать динамическое количество голов у модели,\n",
        "* Также, можно добавить доп конволюцию (3х3 с паддингом) у каждого выхода шеи."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2119ccb8-7d21-4805-af5c-5a1d8d3a0e06",
      "metadata": {
        "id": "2119ccb8-7d21-4805-af5c-5a1d8d3a0e06"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Neck(nn.Module):\n",
        "    def __init__(self, ):\n",
        "        # YOUR CODE HERE\n",
        "\n",
        "    def forward(self, features):\n",
        "        # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "531f59fe-8248-4b19-aa31-8acecccb0828",
      "metadata": {
        "id": "531f59fe-8248-4b19-aa31-8acecccb0828"
      },
      "source": [
        "### Head [1 балл]\n",
        "\n",
        "В качестве шеи можно выбрать __один из двух__ вариантов:\n",
        "\n",
        "#### 1. Decoupled Head\n",
        "\n",
        "Реализовать Decoupled Head из [YOLOX](https://arxiv.org/abs/2107.08430).\n",
        "<center><img src=\"https://i.ibb.co/BVtBR2R3/Decoupled-head.jpg\"/></center>\n",
        "\n",
        "**TIP**: Возьмите за основу голову из семинара, тк она сильно похожа на Decoupled Head.\n",
        "\n",
        "Изменять количество параметров у шей на разных уровнях не обязательно.\n",
        "\n",
        "#### 2. Confidence score free head\n",
        "\n",
        "Нужно взять за основу голову из семинара и полностью убрать предсказание confidence score. Чтобы модель предсказывала только 2 группы: ббоксы и классы.\n",
        "\n",
        "Есть следующие способы удаления confidence score:\n",
        "* Добавление нового класса ФОН. Обычно его обозначают нулевым классом.\n",
        "* Присваивание ббоксам БЕЗ объекта вектор из нулей в качестве таргета.\n",
        "\n",
        "Выберете тот, который вам больше нравится и будте внимательны при расчете лосса!\n",
        "\n",
        "**Важно!** Удаление confidence score повлияет на следующие методы из семинара:\n",
        "* target_assign\n",
        "* ComputeLoss\n",
        "* _filter_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f223b6ca-9498-4e75-9b97-6199c82977e1",
      "metadata": {
        "id": "f223b6ca-9498-4e75-9b97-6199c82977e1"
      },
      "outputs": [],
      "source": [
        "class Head(nn.Module):\n",
        "    def __init__(self, ...):\n",
        "        # YOUR CODE HERE\n",
        "\n",
        "    def forward(self, x):\n",
        "        # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88025100-78a7-4aba-b4f5-e1547b170f24",
      "metadata": {
        "id": "88025100-78a7-4aba-b4f5-e1547b170f24"
      },
      "source": [
        "Теперь можно снова реализовать класс детектора с учетом всех частей выше!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dd8bcb8-149f-4916-b37f-8ba0be54a4c9",
      "metadata": {
        "id": "4dd8bcb8-149f-4916-b37f-8ba0be54a4c9"
      },
      "outputs": [],
      "source": [
        "class Detector(nn.Module):\n",
        "    # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bc104b6-0960-404d-805c-ec880dc9bfb0",
      "metadata": {
        "id": "9bc104b6-0960-404d-805c-ec880dc9bfb0"
      },
      "source": [
        "## Label assignment [2]\n",
        "В этой секции предлагается заменить функцию `assign_target` на более современный алгоритм который называется Task alignment learning.\n",
        "\n",
        "Он описан в статье [TOOD](https://arxiv.org/abs/2108.07755) в секции 3.2. Для удобства вот его основные шаги:\n",
        "\n",
        "1. Посчитать значение метрики для каждого предсказанного ббокса:\n",
        "    \n",
        "$$t = s^\\alpha * u^\\beta$$\n",
        "    \n",
        "где,\n",
        "* $s$ — classification score, или вероятность принадлежности предсказанного ббокса к классу реального ббокса (**GT**);\n",
        "* $u$ — IoU между предсказанным и реальным ббоксами;\n",
        "* $\\alpha,\\ \\beta$ — нормализационные константы, обычно $\\alpha = 6.0, \\ \\beta = 1.0$.\n",
        "    \n",
        "2. Отфильтровать предсказания на основе **GT**.\n",
        "\n",
        "    Для якорных детекторов, обычно, выбираются только те предсказания, центры якорей которых находятся внутри GT.\n",
        "4. Для каждого **GT** выбрать несколько (обычно 5 или 13) самых подходящих предсказаний.\n",
        "5. Если предсказание рассматривается в качестве подходящего для нескольких **GT** — выбрать **GT** с наибольшим пересечением по IoU.\n",
        "\n",
        "\n",
        "**BAЖНО**: если будете использовать Runner из лекции, не забудьте поменять параметры  в `self.assign_target_method` в методе `_run_train_epoch`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a88e418e-2fd5-4f7b-9675-f91db3c52ec5",
      "metadata": {
        "id": "a88e418e-2fd5-4f7b-9675-f91db3c52ec5"
      },
      "outputs": [],
      "source": [
        "def TAL_assigner(...):\n",
        "    # YOUR CODE HERE!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28f25b75-58ed-44e7-adca-c5d518a7467b",
      "metadata": {
        "id": "28f25b75-58ed-44e7-adca-c5d518a7467b"
      },
      "source": [
        "### DIoU [1]\n",
        "\n",
        "Вместо SmoothL1, который используется в семинаре, реализуем лосс, основанный на пересечении ббоксов. В качестве тренировки давайте напишем Distance Intersection over Union (DIoU).\n",
        "\n",
        "<center><img src=https://wikidocs.net/images/page/163613/Free_Fig_5.png></center>\n",
        "\n",
        "Для его реализации разобъем задачу на части:\n",
        "\n",
        "**1. Реализуем IoU:**\n",
        "\n",
        "Пусть даны координаты для предсказанного ($B^p$) и истинного ($B^g$) ббоксов в формате XYXY или VOC PASCAL (левый верхний и правый нижний углы):\n",
        "\n",
        "$B^p=(x^p_1, y^p_1, x^p_2, y^p_2)$, $B^g=(x^g_1, y^g_1, x^g_2, y^g_2)$, тогда алгоритм расчета будет следующий:\n",
        "\n",
        "    1. Найдем площади обоих ббоксов:\n",
        "$$ A^p = (x^p_2 - x^p_1) * (y^p_2 - y^p_1) $$\n",
        "$$ A^g = (x^g_2 - x^g_1) * (y^g_2 - y^g_1) $$\n",
        "\n",
        "    2. Посчитаем пересечение между ббоксами:\n",
        "\n",
        "Тут мы предлагаем вам подумать как в общем виде можно расчитать размеры ббокса, который будет являться пересечением $B^p$ и $B^g$, а затем посчитать его площадь:\n",
        "\n",
        "$$x^I_1 = \\qquad \\qquad y^I_1 = $$\n",
        "$$x^I_2 = \\qquad \\qquad y^I_2 = $$\n",
        "\n",
        "В общем виде, площать будет записываться следующим образом:\n",
        "\n",
        "Если $x^I_2 > x^I_1$ & $y^I_2 > y^I_1$, тогда:\n",
        "\n",
        "$$I = (x^I_2 - x^I_1) * (y^I_2 - y^I_1)$$\n",
        "\n",
        "Иначе, $I = 0$.\n",
        "\n",
        "    3. Считаем объединение ббоксов.\n",
        "\n",
        "Мы можем посчитать эту площадь как сумму площадей двух ббоксов минус площадь пересечения (тк мы считаем её два раз в сумме площадей):\n",
        "\n",
        "$$U = A^p + A^g - I$$\n",
        "\n",
        "    4. Вычисляем IoU.\n",
        "\n",
        "$$IoU = \\frac{I}{U}$$\n",
        "\n",
        "**2. Рассчитаем площадь выпуклой оболочки:**\n",
        "\n",
        "Для расчета площади, сначала выпишите координаты верхнего левого и правого нижнего углов. Подумайте, чему будут равны эти координаты в общем случае?\n",
        "\n",
        "$$x^С_1 = \\qquad \\qquad y^С_1 = $$\n",
        "$$x^С_2 = \\qquad \\qquad y^С_2 = $$\n",
        "\n",
        "Подсказка: Нарисуйте несколько вариантов пересечений предсказания и GT на бумажке, и выпишите координаты для выпуклой оболочки.\n",
        "\n",
        "$$C = (x^C_2 - x^C_1) * (y^C_2 - y^C_1)$$\n",
        "\n",
        "**3. Рассчитаем расстояние между цетрами ббоксов:**\n",
        "\n",
        "Сначала находим координаты центров каждого из ббоксов (если ббоксы в формате YOLO, то и считать ничего не нужно), затем считаем Евклидово расстояние между центрами.\n",
        "\n",
        "$d = $\n",
        "\n",
        "Собираем все части вместе и считаем лосс по формуле:\n",
        "\n",
        "$$ DIoU = 1 - IoU + \\frac{d^2}{C^2}$$\n",
        "\n",
        "Помните, что пар ббоксов может быть много! Возвращайте усредненное значение лосса."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c3740d0-76f7-43b6-a4bd-5ab7048d0c70",
      "metadata": {
        "id": "0c3740d0-76f7-43b6-a4bd-5ab7048d0c70"
      },
      "outputs": [],
      "source": [
        "from torchvision.ops import distance_box_iou_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c412008-e90e-4087-9725-6f4777dc3c8b",
      "metadata": {
        "id": "1c412008-e90e-4087-9725-6f4777dc3c8b"
      },
      "outputs": [],
      "source": [
        "def gen_bbox(num_boxes=10):\n",
        "    min_corner = torch.randint(0, 100, (num_boxes, 2))\n",
        "    max_corner = torch.randint(50, 150, (num_boxes, 2))\n",
        "\n",
        "    for i in range(2):\n",
        "        wrong_order = min_corner[:, i] > max_corner[:, i]\n",
        "        if wrong_order.any():\n",
        "            min_corner[wrong_order, i], max_corner[wrong_order, i] = max_corner[wrong_order, i], min_corner[wrong_order, i]\n",
        "    return torch.cat((min_corner, max_corner), dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c764214-2797-4111-8e5f-d421dad9aae6",
      "metadata": {
        "id": "6c764214-2797-4111-8e5f-d421dad9aae6"
      },
      "outputs": [],
      "source": [
        "pred_boxes = gen_bbox(num_boxes=100)\n",
        "true_boxes = gen_bbox(num_boxes=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24a64210-29a0-4b1a-a0d1-c690b1955801",
      "metadata": {
        "id": "24a64210-29a0-4b1a-a0d1-c690b1955801"
      },
      "outputs": [],
      "source": [
        "print(f\" DIoU: {distance_box_iou_loss(pred_boxes, true_boxes, reduction=\"mean\").item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dd590f7-59fc-4aae-93cd-23dc01d8cf3d",
      "metadata": {
        "id": "2dd590f7-59fc-4aae-93cd-23dc01d8cf3d"
      },
      "outputs": [],
      "source": [
        "def diou_loss(pred_boxes, gt_boxes):\n",
        "  # TODO\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "169ebd6b-c45f-4b7d-a456-ff3e95619136",
      "metadata": {
        "id": "169ebd6b-c45f-4b7d-a456-ff3e95619136"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "pred_boxes = gen_bbox(num_boxes=1000)\n",
        "true_boxes = gen_bbox(num_boxes=1000)\n",
        "\n",
        "# проверим что написанный лосс выдает те же результаты что и лосс из торча.\n",
        "assert np.isclose(diou_loss(pred_boxes, true_boxes), distance_box_iou_loss(pred_boxes, true_boxes, reduction=\"mean\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1167d47f-9a56-40e2-9bb2-f8e749c5e499",
      "metadata": {
        "id": "1167d47f-9a56-40e2-9bb2-f8e749c5e499"
      },
      "source": [
        "## Кто больше? [5 баллов]\n",
        "\n",
        "Наконец то мы дошли до самый интересной части. Тут мы раздаем очки за mAP'ы!\n",
        "\n",
        "Все что вы написали выше вам поможет улучшить качество итогового детектора, настало время узнать насколько сильно :)\n",
        "\n",
        "За достижения порога по mAP на тестовом наборе вы получаете баллы:\n",
        "* 0.15 mAP [1]\n",
        "* 0.3 mAP [2]\n",
        "* 0.6 mAP [5]\n",
        "\n",
        "\n",
        "**TIPS**:\n",
        "1. На семинаре мы специально не унифицировали формат ббоксов между методами, чтобы обратить ваше внимание что за этим нужно следить. Чтобы было проще, сразу унифицируете формат по всему ноутбуку. Советуем использовать формат xyxy, тк IoU и NMS из torch используют именно этот формат. (Не забудьте поменять формат у таргета в `HaloDataset`).\n",
        "2. Попробуйте перейти к IoU-based лоссу при обучении. То есть обучать не смещения, а сразу предсказывать ббокс.\n",
        "3. Поэксперементируйте с подходами target assignment'а в процессе обучения. Например, можно на первых итерациях использовать обычный метод, а затем подключить TAL.\n",
        "4. Добавьте аугментаций!\n",
        "\n",
        "   Можно взять [albumentations](https://albumentations.ai/docs/getting_started/bounding_boxes_augmentation/), библиотеку, которую мы использовали всеминаре. Или базовые аугментации из торча [тык](https://pytorch.org/vision/main/transforms.html). Если будете использовать торч, не забудте про ббоксы, transforms из коробки не будет их агументировать.\n",
        "7. Попробуйте добавлять различные блоки из YOLO архитектур в шею вместо единичных конволюционных слоев. (Например, замените конволюции 3х3 на CSP блоки).\n",
        "8. Попробуйте заменить NMS на другой метод (WeightedNMS, SoftNMS, etc.). Немного ссылок:\n",
        "    * Статья про SoftNMS [тык](https://arxiv.org/pdf/1704.04503)\n",
        "    * Статья про WeightedNMS [тык](https://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w14/Zhou_CAD_Scale_Invariant_ICCV_2017_paper.pdf)\n",
        "    * Есть их реализация, правда на нумбе [git](https://github.com/ZFTurbo/Weighted-Boxes-Fusion?tab=readme-ov-file)\n",
        "10. Не бойтесь эксперементировать и удачи!\n",
        "\n",
        "Также, напишите развернутые ответы на следующие вопросы:\n",
        "\n",
        "**Questions:**\n",
        "1. Какой метод label assignment'a помогает лучше обучаться модели? Почему?\n",
        "2. Какое из сделаных вами улучшений внесло наибольший вклад в качество модели? Как вы думаете, почему это произошло?\n",
        "3. Какое из сделанных вами улучшений вообще не изменило метрику? Как вы думаете, почему это произошло?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f0b3ca5-c7cb-4bfd-a999-a88df9ee56b8",
      "metadata": {
        "id": "4f0b3ca5-c7cb-4bfd-a999-a88df9ee56b8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Место для обучения, валидации и экспериментов!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ea5c0ec-c738-4c11-b6ec-dd1bf9a9491d",
      "metadata": {
        "id": "6ea5c0ec-c738-4c11-b6ec-dd1bf9a9491d"
      },
      "source": [
        "Ниже определена вспомогательная функция для валидации качества. Можете использовать `Runner.validate`. Важное уточнение, ей нужен метод для фильтрации предсказаний. Можете тоже скопировать его из семинара, если он у вас не менялся."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "299b193f-b697-449d-b4c0-3ef57c77eb7e",
      "metadata": {
        "id": "299b193f-b697-449d-b4c0-3ef57c77eb7e"
      },
      "outputs": [],
      "source": [
        "from torchmetrics.detection import MeanAveragePrecision\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate(dataloader, filter_predictions_func, box_format=\"xyxy\", device=\"cpu\", score_threshold=0.1, nms_threshold=0.5, **kwargs):\n",
        "    \"\"\" Метод для валидации модели.\n",
        "    Возвращает mAP (0.5 ... 0.95).\n",
        "    \"\"\"\n",
        "    self.model.eval()\n",
        "    # Считаем метрику mAP с помощью функции из torchmetrics\n",
        "    metric = MeanAveragePrecision(box_format=box_format, iou_type=\"bbox\")\n",
        "    for images, targets in tqdm(dataloader, desc=\"Running validation\", leave=False):\n",
        "        images = images.to(device)\n",
        "        outputs = self.model(images)\n",
        "        predicts = filter_predictions_func(outputs, score_threshold, nms_threshold, **kwargs)\n",
        "        metric.update(predicts, targets)\n",
        "    return metric.compute()[\"map\"].item()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}