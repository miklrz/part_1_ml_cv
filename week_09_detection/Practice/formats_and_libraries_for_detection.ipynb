{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "99f97cb7-a4ec-49c1-ab65-448038e02b15",
      "metadata": {
        "id": "99f97cb7-a4ec-49c1-ab65-448038e02b15"
      },
      "source": [
        "## Обзор основных форматов для задачи детекции\n",
        "\n",
        "Ноутбук состоит из двух частей:\n",
        "1. Разбор описания ббоксов на примере датасетов-бенчмарков и не только:\n",
        "    * Pascal VOC\n",
        "    * COCO\n",
        "    * Open Images\n",
        "    * YOLO\n",
        "2. Как можно написать детектор за пару строчек кода используя готовые реализации:\n",
        "    * TorchVision\n",
        "    * Ultralytics\n",
        "    * Detectron2\n",
        "    * mmdetection\n",
        "\n",
        "### Pascal VOC format\n",
        "Это один из самых первых форматов.\n",
        "\n",
        "Для аннотации используется XML:\n",
        "```XML\n",
        "<annotation>\n",
        "    <filename>000001.jpg</filename>\n",
        "    <size>\n",
        "        <width>500</width>\n",
        "        <height>375</height>\n",
        "        <depth>3</depth>\n",
        "    </size>\n",
        "    <object>\n",
        "        <name>helmet</name>\n",
        "        <pose>Unspecified</pose>\n",
        "        <truncated>0</truncated>\n",
        "        <difficult>0</difficult>\n",
        "        <occluded>0</occluded>\n",
        "        <bndbox>\n",
        "            <xmin>179</xmin>\n",
        "            <ymin>85</ymin>\n",
        "            <xmax>231</xmax>\n",
        "            <ymax>144</ymax>\n",
        "        </bndbox>\n",
        "    </object>\n",
        "</annotation>\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cb24278-ef93-40d0-80e2-b65b4c8cb456",
      "metadata": {
        "id": "4cb24278-ef93-40d0-80e2-b65b4c8cb456"
      },
      "source": [
        "### COCO 2017 dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a2c29d2-914b-4fb5-8545-212ce9481978",
      "metadata": {
        "id": "9a2c29d2-914b-4fb5-8545-212ce9481978"
      },
      "source": [
        "Давайте посмотрим на то как выглядит датасет COCO (При желании можете его скачать ~20гб)\n",
        "\n",
        "Весь датасет лежит вот тут: https://cocodataset.org/#download.\n",
        "\n",
        "Инструкция для желающих:\n",
        "\n",
        "Разметка существует для двух частей датасета: `train` и `val`, скачать их можно по ссылкам ниже:\n",
        "```\n",
        "!wget http://images.cocodataset.org/zips/train2017.zip\n",
        "!wget http://images.cocodataset.org/zips/val2017.zip\n",
        "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
        "```\n",
        "`annotations_tranval2017` это файл с разметкой для данных из трейна и валидации.\n",
        "\n",
        "При желании, можете скачать тестовые данные:\n",
        "```\n",
        "!wget http://images.cocodataset.org/zips/test2017.zip\n",
        "```\n",
        "\n",
        "Затем, расархивируем скаченные данные:\n",
        "\n",
        "```\n",
        "!unzip train2017.zip\n",
        "!unzip val2017.zip\n",
        "!unzip annotations_trainval2017.zip\n",
        "```\n",
        "\n",
        "Можно создать отдельную папку для датасета и сложить всю датку туда:\n",
        "\n",
        "```\n",
        "!mkdir coco\n",
        "!mv train2017 coco/\n",
        "!mv val2017 coco/\n",
        "```\n",
        "\n",
        "Давайте посмотрим что за данные там лежат и в каком формате"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aced371b-c08b-4d93-a638-a748f8bff06c",
      "metadata": {
        "id": "aced371b-c08b-4d93-a638-a748f8bff06c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from pycocotools.coco import COCO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6031d9e4-8a4f-4a96-9ba4-4cd819735cec",
      "metadata": {
        "id": "6031d9e4-8a4f-4a96-9ba4-4cd819735cec"
      },
      "outputs": [],
      "source": [
        "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
        "!unzip annotations_trainval2017.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5c21173-344f-4664-a152-4d2fc8c68192",
      "metadata": {
        "id": "b5c21173-344f-4664-a152-4d2fc8c68192"
      },
      "source": [
        "Структура аннотаций следующая:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93d7f532-0659-469d-a633-04fe02e4baa3",
      "metadata": {
        "id": "93d7f532-0659-469d-a633-04fe02e4baa3"
      },
      "outputs": [],
      "source": [
        "!ls -l annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccbb706f-8edd-406e-a10d-210ceacac5b2",
      "metadata": {
        "id": "ccbb706f-8edd-406e-a10d-210ceacac5b2"
      },
      "outputs": [],
      "source": [
        "coco=COCO(\"annotations/instances_val2017.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa05dd31-701c-49a3-8690-431728bcd750",
      "metadata": {
        "id": "fa05dd31-701c-49a3-8690-431728bcd750"
      },
      "source": [
        "Посмотрим на картинку с аннтоацией"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bc5e2af-c023-4dfd-8b81-76c6ca10bf8f",
      "metadata": {
        "id": "7bc5e2af-c023-4dfd-8b81-76c6ca10bf8f"
      },
      "outputs": [],
      "source": [
        "import skimage.io as io\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Чтобы посмотреть примеры, нам не нужно скачивать датасет!\n",
        "img = coco.loadImgs(84492)[0]\n",
        "I = io.imread(img['coco_url'])\n",
        "plt.imshow(I); plt.axis('off')\n",
        "\n",
        "annIds = coco.getAnnIds(imgIds=img['id'], iscrowd=None)\n",
        "anns = coco.loadAnns(annIds)\n",
        "coco.showAnns(anns, draw_bbox=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a9d5b3c-be63-4443-adc3-fee3c7bb85de",
      "metadata": {
        "id": "1a9d5b3c-be63-4443-adc3-fee3c7bb85de"
      },
      "source": [
        "Cам файл с аннтацией выглядит следующим образом:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98da8c11-8eb9-488d-81cd-d753f918ebc8",
      "metadata": {
        "scrolled": true,
        "id": "98da8c11-8eb9-488d-81cd-d753f918ebc8"
      },
      "outputs": [],
      "source": [
        "anns[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16eb08ca-cf01-488c-bdf4-f5e4736ff4e4",
      "metadata": {
        "id": "16eb08ca-cf01-488c-bdf4-f5e4736ff4e4"
      },
      "source": [
        "А вот общая структура COCO аннотаций:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"images\": [\n",
        "        {\n",
        "            \"id\": 0,\n",
        "            \"file_name\": \"0001.jpg\",\n",
        "            \"width\": 490,\n",
        "            \"height\": 275\n",
        "        }\n",
        "    ],\n",
        "    \"annotations\": [\n",
        "        {\n",
        "            \"id\": 0,\n",
        "            \"image_id\": 0,\n",
        "            \"category_id\": 2,\n",
        "            \"bbox\": [45, 2, 85, 85],\n",
        "            \"area\": 7225,\n",
        "            \"segmentation\": [],\n",
        "            \"iscrowd\": 0\n",
        "        },\n",
        "        {\n",
        "            \"id\": 1,\n",
        "            \"image_id\": 0,\n",
        "            \"category_id\": 2,\n",
        "            \"bbox\": [324, 29, 72, 81],\n",
        "            \"area\": 5832,\n",
        "            \"segmentation\": [],\n",
        "            \"iscrowd\": 0\n",
        "        }\n",
        "    ],\n",
        "    \"categories\": [\n",
        "        { \"id\": 0, \"name\": \"Workers\", \"supercategory\": \"none\" },\n",
        "        { \"id\": 1, \"name\": \"head\",    \"supercategory\": \"Workers\" },\n",
        "        { \"id\": 2, \"name\": \"helmet\",  \"supercategory\": \"Workers\" }\n",
        "    ]\n",
        "}\n",
        "```\n",
        "\n",
        "### Open Images\n",
        "\n",
        "Формат датасета Open Images - CSV-аннотации в одном или нескольких файлах:\n",
        "* Формат ббоксов:\n",
        "```csv\n",
        "ImageID,Source,LabelName,Confidence,XMin,XMax,YMin,YMax,IsOccluded,IsTruncated,IsGroupOf,IsDepiction,IsInside,XClick1X,XClick2X,XClick3X,XClick4X,XClick1Y,XClick2Y,XClick3Y,XClick4Y\n",
        "000002b66c9c498e,xclick,/m/04bcr3,1,0.312500,0.578125,0.351562,0.464063,0,0,0,0,0,0.312500,0.578125,0.385937,0.576562,0.454688,0.364063,0.351562,0.464063\n",
        "3550e6ef5d44d91a,activemil,/m/0220r2,1,0.022461,0.865234,0.234375,0.986979,1,0,0,0,0,-1.000000,-1.000000,-1.000000,-1.000000,-1.000000,-1.000000,-1.000000,-1.000000\n",
        "880b4b00f75260ec,xclick,/m/0ch_cf,1,0.641875,0.693125,0.818333,0.878333,1,0,0,0,0,0.641875,0.643125,0.678750,0.693125,0.818333,0.842500,0.871667,0.878333\n",
        "b17e3f11cb77c7c8,xclick,/m/0dzct,1,0.510156,0.664844,0.337632,0.623681,1,0,0,0,0,0.573438,0.510156,0.664844,0.587500,0.337632,0.438453,0.468933,0.623681\n",
        "```\n",
        "\n",
        "Каждая строчка - отдельный ббокс.\n",
        "\n",
        "* Изображения и классы:\n",
        "Классы лежат в csv-файле , в котором есть класс и ID картики. Сами картинки это JPEG которые лежат по разным директориям (train/val/test)\n",
        "\n",
        "### YOLO\n",
        "\n",
        "Самый простой формат - для каждого файла, аннотации хранятся в отдельном файле `.TXT`.\n",
        "\n",
        "Формат файла:\n",
        "```\n",
        "<class_id> <x_center> <y_center> <width> <height>\n",
        "```\n",
        "Пример:\n",
        "`img_id.txt`\n",
        "```\n",
        "1 0.408 0.3027 0.104 0.1573\n",
        "1 0.245 0.4240 0.046 0.0800\n",
        "```\n",
        "\n",
        "#### Ultralytics YOLO format\n",
        "\n",
        "Из туториала по датасетам [[ссылка](https://docs.ultralytics.com/datasets/detect/)]\n",
        "\n",
        "В качестве датасета Ultralytics принимает yaml файл со следующей структурой:\n",
        "```\n",
        "# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]\n",
        "\n",
        "path: ../datasets/coco8 # dataset root dir (absolute or relative; if relative, it's relative to default datasets_dir)\n",
        "train: images/train # train images (relative to 'path') 4 images\n",
        "val: images/val # val images (relative to 'path') 4 images\n",
        "test: # test images (optional)\n",
        "\n",
        "# Classes (80 COCO classes)\n",
        "names:\n",
        "    0: person\n",
        "    1: bicycle\n",
        "    2: car\n",
        "    # ...\n",
        "    77: teddy bear\n",
        "    78: hair drier\n",
        "    79: toothbrush\n",
        "```\n",
        "Пример датасета:\n",
        "![image.png](https://github.com/ultralytics/docs/releases/download/0/two-persons-tie-2.avif)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc4c9ec6-9798-4a6d-8b3c-4c2b0b09baef",
      "metadata": {
        "id": "fc4c9ec6-9798-4a6d-8b3c-4c2b0b09baef"
      },
      "source": [
        "## Пишем детектор за пару строк кода\n",
        "### TorchVision\n",
        "\n",
        "#### Инференс"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d880fb7-833e-49d2-bf8f-0bb9ca298361",
      "metadata": {
        "id": "1d880fb7-833e-49d2-bf8f-0bb9ca298361"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch, torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import draw_bounding_boxes, draw_segmentation_masks\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Загружаем модель fasterrcnn с бекбоуном resnet50\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
        "model.eval().to(device)\n",
        "\n",
        "# Открваем любое изображение\n",
        "# image = Image.open(\"image.jpg\")\n",
        "# Возмем изображение из COCO\n",
        "image = np.array(I)\n",
        "img_tensor = transforms.ToTensor()(image).to(device)\n",
        "\n",
        "# Делаем инференс модели\n",
        "with torch.no_grad():\n",
        "    outputs = model([img_tensor])\n",
        "\n",
        "# Извлекаем предсказанные рамки, метки и скоры для первого изображения\n",
        "pred_boxes = outputs[0]['boxes']\n",
        "pred_scores = outputs[0]['scores']\n",
        "pred_labels = outputs[0]['labels']\n",
        "print(\"Detected\", len(pred_boxes), \"objects\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f34a597-3f8b-428f-a689-8c1383f3334e",
      "metadata": {
        "id": "9f34a597-3f8b-428f-a689-8c1383f3334e"
      },
      "source": [
        "Нарисуем предсказанные ббоксы:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71ba649e-f3e4-4502-a7f4-5a33032118b1",
      "metadata": {
        "id": "71ba649e-f3e4-4502-a7f4-5a33032118b1"
      },
      "outputs": [],
      "source": [
        "def plot_boxes(torch_img, torch_boxes_xyxy):\n",
        "    image = (255.0 * (torch_img - torch_img.min()) / (torch_img.max() - torch_img.min())).to(torch.uint8)\n",
        "    image = image[:3, ...]\n",
        "    output_image = draw_bounding_boxes(image, torch_boxes_xyxy.long(), None)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.imshow(output_image.permute(1, 2, 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdd08112-b661-4ea7-a413-c361780f1109",
      "metadata": {
        "id": "cdd08112-b661-4ea7-a413-c361780f1109"
      },
      "outputs": [],
      "source": [
        "plot_boxes(img_tensor, pred_boxes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "304d13ba-59ef-476d-b769-487082c0de70",
      "metadata": {
        "id": "304d13ba-59ef-476d-b769-487082c0de70"
      },
      "source": [
        "#### Дообучение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93ab4739-ca06-47e7-b9a0-f60ae6b8dd28",
      "metadata": {
        "id": "93ab4739-ca06-47e7-b9a0-f60ae6b8dd28"
      },
      "outputs": [],
      "source": [
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "\n",
        "# Заменяем голову (классификатор) у pre-trained Faster R-CNN и меняем у неё количество классов на нужное нам\n",
        "num_classes = 3  # например, 2 класса + фон\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes).to(device)\n",
        "\n",
        "# Оптимизатор\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9)\n",
        "\n",
        "num_epochs = 10\n",
        "train_loader = # YOUR BEST TRAIN LOADER\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    for images, targets in train_loader:\n",
        "        images = images.to(device)\n",
        "        # при необходимости можем перенести таргеты на GPU\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        # обучаем модель\n",
        "        loss_dict = model(images, targets)\n",
        "        total_loss = sum(loss for loss in loss_dict.values())\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "        print(f\"total loss: {total_loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f287bff-c567-418d-af2c-509486199c4e",
      "metadata": {
        "id": "8f287bff-c567-418d-af2c-509486199c4e"
      },
      "source": [
        "Плюсы:\n",
        "* Из коробки рабочий детектор на торче, удобно кастомизировать,\n",
        "* Обучается как любая другая torch модель.\n",
        "\n",
        "Минусы:\n",
        "* Небольшой выбор реализованных моделей,\n",
        "* Возможно, придется много реализовывать самостоятельно."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39f50d97-a9ff-4f70-b2fa-3b9e40f9ddc2",
      "metadata": {
        "id": "39f50d97-a9ff-4f70-b2fa-3b9e40f9ddc2"
      },
      "source": [
        "### Ultralytics\n",
        "[[github](https://github.com/ultralytics/ultralytics)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70a96a06-afec-437d-a7e0-b70bb5b61ada",
      "metadata": {
        "scrolled": true,
        "id": "70a96a06-afec-437d-a7e0-b70bb5b61ada"
      },
      "outputs": [],
      "source": [
        "# Раскомментируйте, если выполняете из коллаба\n",
        "# !pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc81a4c7-3b91-4b18-b1d7-33188399ad0d",
      "metadata": {
        "scrolled": true,
        "id": "bc81a4c7-3b91-4b18-b1d7-33188399ad0d"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Скачали маленькую YOLOv8 в одну строчку\n",
        "model = YOLO(\"yolov8n.pt\").to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e7c7a7f-ffe6-43a3-8af8-671fbb755133",
      "metadata": {
        "id": "2e7c7a7f-ffe6-43a3-8af8-671fbb755133"
      },
      "source": [
        "#### Инференс"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3658fa1f-cbcf-4b98-80df-3adc7846dd18",
      "metadata": {
        "id": "3658fa1f-cbcf-4b98-80df-3adc7846dd18"
      },
      "outputs": [],
      "source": [
        "image = np.array(I)\n",
        "img_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((640, 640)),\n",
        "])\n",
        "img_tensor = img_transforms(image).to(device)\n",
        "results = model(img_tensor[None,])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da29f054-6561-42f6-a62c-a75b54c70787",
      "metadata": {
        "id": "da29f054-6561-42f6-a62c-a75b54c70787"
      },
      "outputs": [],
      "source": [
        "# ббоксы на изображении\n",
        "results[0].boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdfa6c42-4241-4a67-9b91-379df261e76d",
      "metadata": {
        "id": "bdfa6c42-4241-4a67-9b91-379df261e76d"
      },
      "outputs": [],
      "source": [
        "plot_boxes(img_tensor, results[0].boxes.xyxy)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b4af1d0-4863-4bf4-a51c-c40be45932c2",
      "metadata": {
        "id": "8b4af1d0-4863-4bf4-a51c-c40be45932c2"
      },
      "source": [
        "#### Обучение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01d32ae7-9f71-41f6-aed4-23d00fc54835",
      "metadata": {
        "id": "01d32ae7-9f71-41f6-aed4-23d00fc54835"
      },
      "outputs": [],
      "source": [
        "# задаем описание датасета в yaml и обучаем модель.\n",
        "\n",
        "results = model.train(data=\"my_dataset.yaml\", epochs=10, batch=8, device=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f107b499-2cb2-4e4e-8b90-9859f2643b24",
      "metadata": {
        "id": "f107b499-2cb2-4e4e-8b90-9859f2643b24"
      },
      "source": [
        "Плюсы:\n",
        "* Простота использования,\n",
        "* Быстрые и качественные модели,\n",
        "* Простой и понятный формат аннотаций,\n",
        "* Хорошая экосистема, в которой есть все для обучения и деплоя:\n",
        "    * Автоматические расчеты статистик по датасету,\n",
        "    * Подключение clearml во время обучения ([link](https://www.ultralytics.com/blog/remotely-train-and-monitor-yolov5-using-clearml))\n",
        "    * Логирование в процессе обучения, можно просматривать ббоксы на различных итерациях обучения ([link](https://docs.wandb.ai/guides/integrations/ultralytics/))\n",
        "    * Прекомит хуки ([link](https://github.com/ultralytics/pre-commit))\n",
        "\n",
        "Минусы:\n",
        "* Сосредоточены именно на YOLO моделях, мало других детекторов\n",
        "* Низкая возможность кастомизации моделей."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e0887d1-516f-4da8-8fcd-1f58ed58f1d7",
      "metadata": {
        "id": "3e0887d1-516f-4da8-8fcd-1f58ed58f1d7"
      },
      "source": [
        "### Detectron2\n",
        "\n",
        "Это библиотека от Facebook AI Research [[github](https://github.com/facebookresearch/detectron2)], colab tutorial [[link](https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5)].\n",
        "\n",
        "Быстрая установка библиотеки:\n",
        "```\n",
        "!python -m pip install pyyaml==5.1\n",
        "import sys, os, distutils.core\n",
        "# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities (e.g. compiled operators).\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n",
        "!git clone 'https://github.com/facebookresearch/detectron2'\n",
        "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
        "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
        "sys.path.insert(0, os.path.abspath('./detectron2'))\n",
        "```\n",
        "\n",
        "ИЛИ\n",
        "\n",
        "Полная установка\n",
        "```\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a91ed97-1441-417c-ba4c-574a4f14c64c",
      "metadata": {
        "id": "4a91ed97-1441-417c-ba4c-574a4f14c64c"
      },
      "outputs": [],
      "source": [
        "# раскомментировать в коллабе!\n",
        "# from google.colab.patches import cv2_imshow\n",
        "\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "\n",
        "# Снова берем картинку из COCO\n",
        "image = np.array(I)\n",
        "\n",
        "# Библиотека использует конфиги. Давайте создадим самый простой конфиг\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(\"detectron2/configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n",
        "cfg.MODEL.WEIGHTS = \"detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl\"\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # порог уверенности\n",
        "cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Создаем предиктор и выполняем предсказание\n",
        "predictor = DefaultPredictor(cfg)\n",
        "outputs = predictor(image)\n",
        "\n",
        "# Достаем предсказанные боксы, классы и оценки\n",
        "instances = outputs[\"instances\"].to(\"cpu\")\n",
        "print(\"Number of detectins\", len(instances.pred_boxes))\n",
        "print(instances.pred_boxes, instances.scores, instances.pred_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48af83ca-f7aa-4ee8-ad12-c8eb104db6f4",
      "metadata": {
        "id": "48af83ca-f7aa-4ee8-ad12-c8eb104db6f4"
      },
      "outputs": [],
      "source": [
        "v = Visualizer(image[:, :, ::-1], scale=1.2)\n",
        "out = v.draw_instance_predictions(outputs[\"instances\"].to(device))\n",
        "cv2_imshow(out.get_image())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90c99fe9-16ab-4338-bdf7-f87e4eba9390",
      "metadata": {
        "id": "90c99fe9-16ab-4338-bdf7-f87e4eba9390"
      },
      "source": [
        "#### Инференс\n",
        "Чтобы сделать инференс на своем датасете его нужно зарегистрировать:\n",
        "```\n",
        "# DatasetCatalog.register(\"my_dataset_train\", <функция загрузки аннотаций>)\n",
        "# MetadataCatalog.get(\"my_dataset_train\").set(thing_classes=[\"класс1\", \"класс2\", ...])\n",
        "```\n",
        "\n",
        "Если датасет в COCO формате, можно написать:\n",
        "\n",
        "```\n",
        "# from detectron2.data.datasets import register_coco_instances\n",
        "# register_coco_instances(\"my_dataset_train\", {}, \"json_annotation_train.json\", \"path/to/image/dir\")\n",
        "# register_coco_instances(\"my_dataset_val\", {}, \"json_annotation_val.json\", \"path/to/image/dir\")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f53efcb8-95d6-40db-b36e-e952f86c2e89",
      "metadata": {
        "id": "f53efcb8-95d6-40db-b36e-e952f86c2e89"
      },
      "outputs": [],
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "# далее создаем конфиг для обучения\n",
        "\n",
        "cfg = get_cfg()\n",
        "# в библиотеке есть папка с конфигами дефолтных моделей\n",
        "cfg.merge_from_file(\"configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n",
        "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
        "cfg.DATASETS.TEST = ()  # можно указать validation датасет\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = \"detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl\"\n",
        "cfg.SOLVER.IMS_PER_BATCH = 4\n",
        "cfg.SOLVER.BASE_LR = 0.00025\n",
        "cfg.SOLVER.MAX_ITER = 1000\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = num_classes  # кол-во классов (без фона)\n",
        "\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d1e3244-31e1-46ac-aed1-e501e880d898",
      "metadata": {
        "id": "3d1e3244-31e1-46ac-aed1-e501e880d898"
      },
      "source": [
        "Плюсы:\n",
        "* Разнообразные модели (правда уже старые и в основном Faster R-CNN-based модели),\n",
        "* Большая возможность кастомизации с помощью конфигов\n",
        "* Поддерживает всякие оптимизации (Mixed Precision Training, Multi-GPU / Multi-Node)\n",
        "* Может работать с кастомными датасетами не только для задачи детекции\n",
        "\n",
        "Минусы:\n",
        "* Высокий порог входа,\n",
        "* Требователен к ресурсам"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a45c4552-54ff-45ef-b92c-4baa4ec0cf75",
      "metadata": {
        "id": "a45c4552-54ff-45ef-b92c-4baa4ec0cf75"
      },
      "source": [
        "### mmdetection\n",
        "[[github](https://github.com/open-mmlab/mmdetection)]\n",
        "\n",
        "Можно сказать что это улучшенная версия Detectron2\n",
        "#### Инференс"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70a9cf3b-ce71-4df9-ae90-aec95f6a9e84",
      "metadata": {
        "id": "70a9cf3b-ce71-4df9-ae90-aec95f6a9e84"
      },
      "outputs": [],
      "source": [
        "# Устанавлием mmdetection\n",
        "# install dependencies: (use cu111 because colab has CUDA 11.1)\n",
        "%pip install -U openmim\n",
        "!mim install \"mmengine>=0.7.0\"\n",
        "!mim install \"mmcv>=2.0.0rc4\"\n",
        "\n",
        "# Install mmdetection\n",
        "!rm -rf mmdetection\n",
        "!git clone https://github.com/open-mmlab/mmdetection.git\n",
        "%cd mmdetection\n",
        "\n",
        "%pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78a1e67f-5109-4bea-9708-a41d14f31b56",
      "metadata": {
        "id": "78a1e67f-5109-4bea-9708-a41d14f31b56"
      },
      "outputs": [],
      "source": [
        "# Скачиваем нужную нам модель\n",
        "!mim download mmdet --config rtmdet_tiny_8xb32-300e_coco"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee57fbb5-31f1-45a2-9d7a-a34cc45ade62",
      "metadata": {
        "id": "ee57fbb5-31f1-45a2-9d7a-a34cc45ade62"
      },
      "outputs": [],
      "source": [
        "from mmdet.registry import VISUALIZERS\n",
        "from mmdet.apis import init_detector, inference_detector\n",
        "\n",
        "config_file = \"/root/.cache/mim/rtmdet_tiny_8xb32-300e_coco.py\"\n",
        "checkpoint_file = \"/root/.cache/mim/rtmdet_tiny_8xb32-300e_coco_20220902_112414-78e30dcc.pth\"\n",
        "\n",
        "model = init_detector(config_file, checkpoint_file, device=device)\n",
        "\n",
        "# Выполняем инференс\n",
        "image = np.array(I)\n",
        "result = inference_detector(model, image)\n",
        "\n",
        "# В результате получаем numpy массив с координатами ббоксов и вероятностями для каждого класса\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "436fb6df-21d7-433e-877f-8274e3cd6c05",
      "metadata": {
        "id": "436fb6df-21d7-433e-877f-8274e3cd6c05"
      },
      "outputs": [],
      "source": [
        "# Рисуем предсказания\n",
        "visualizer = VISUALIZERS.build(model.cfg.visualizer)\n",
        "visualizer.dataset_meta = model.dataset_meta\n",
        "\n",
        "visualizer.add_datasample(\n",
        "    'result',\n",
        "    image,\n",
        "    data_sample=result,\n",
        "    draw_gt=False,\n",
        "    wait_time=0,\n",
        ")\n",
        "visualizer.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd2d7d14-8ad4-4246-ae25-b13e6440354e",
      "metadata": {
        "id": "bd2d7d14-8ad4-4246-ae25-b13e6440354e"
      },
      "source": [
        "#### Train\n",
        "Обучение обычно происходит через командную строку. Мы должны создать конфиг файл и передать его в качестве аргумента для метода train.\n",
        "\n",
        "Конфиг в mmdetection это `.py` файл следующей структуры:\n",
        "```py\n",
        "_base_ = \"./faster_rcnn_r50_fpn_1x_coco.py\"\n",
        "num_classes = 3\n",
        "\n",
        "model = dict(\n",
        "    roi_head=dict(\n",
        "        bbox_head=dict(num_classes=num_classes),\n",
        "    )\n",
        ")\n",
        "\n",
        "dataset_type = \"COCODataset\"\n",
        "data = dict(\n",
        "    train=dict(\n",
        "        img_prefix=\"data/train/\",\n",
        "        ann_file=\"data/train/annotations.json\",\n",
        "    ),\n",
        "    val=dict(\n",
        "        img_prefix=\"data/val/\",\n",
        "        ann_file=\"data/val/annotations.json\",\n",
        "    ),\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd2eb3d7-b67f-49c5-a4a8-deeae34021c4",
      "metadata": {
        "id": "cd2eb3d7-b67f-49c5-a4a8-deeae34021c4"
      },
      "outputs": [],
      "source": [
        "# затем выполняем скрипт\n",
        "!mim train mmdet path/to/my_config.py --gpu-id 0 --work-dir ./work_dirs/my_model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba66b070-d00c-4eb4-b1d1-dfa5f4808712",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-10T15:27:55.834092Z",
          "iopub.status.busy": "2025-03-10T15:27:55.833751Z",
          "iopub.status.idle": "2025-03-10T15:27:55.840740Z",
          "shell.execute_reply": "2025-03-10T15:27:55.839674Z",
          "shell.execute_reply.started": "2025-03-10T15:27:55.834055Z"
        },
        "id": "ba66b070-d00c-4eb4-b1d1-dfa5f4808712"
      },
      "source": [
        "Плюсы:\n",
        "* Один из самых мощных фрейморков для обучения моделей,\n",
        "* Поддерживает ещё больше моделей,\n",
        "    * Есть real-time модели типа YOLO\n",
        "* python конфиги более удобный и гибкий инструмент для описания моделей,\n",
        "* Удобная поддержка кастомных датасетов (не нужно их регистрировать как в Detectron2),\n",
        "\n",
        "Минусы:\n",
        "* Ещё больше порог входа."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}