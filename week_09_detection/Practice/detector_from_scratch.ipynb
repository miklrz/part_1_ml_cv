{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dce30db-0bd2-45b4-88d5-efe91d6c9bac",
      "metadata": {
        "id": "6dce30db-0bd2-45b4-88d5-efe91d6c9bac"
      },
      "outputs": [],
      "source": [
        "# Если запускаете из коллаба\n",
        "# pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d867329-7ea2-4819-aba8-b74c4ff3fef5",
      "metadata": {
        "id": "7d867329-7ea2-4819-aba8-b74c4ff3fef5"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from functools import partial\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "import io\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm.auto import tqdm\n",
        "from torchvision import transforms\n",
        "from torchvision.ops import nms, box_iou\n",
        "from torchvision.models.detection.anchor_utils import AnchorGenerator\n",
        "\n",
        "from torchmetrics.detection import MeanAveragePrecision"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a613d75-6578-4c16-94d9-215719ecad7b",
      "metadata": {
        "id": "0a613d75-6578-4c16-94d9-215719ecad7b"
      },
      "source": [
        "# Object Detector from scratch\n",
        "\n",
        "Давайте напишем свой первый детектор с нуля.\n",
        "\n",
        "Сегодня нам предстоит самоятоятельно реализовать следующие вещи:\n",
        "\n",
        "1. Поработать с датасетом,\n",
        "    * Загрузить данные,\n",
        "    * Посмотреть примеры,\n",
        "    * Провести небольшой анализ данных,\n",
        "2. Написать основные методы работы с данными,\n",
        "    * Dataset, Dataloader\n",
        "3. Реализовать детектор по частям,\n",
        "    * Backbone, Neck, Head и общий класс Detector\n",
        "4. Добавить алгоритм обучения модели,\n",
        "    * label assignment,\n",
        "    * Loss computation,\n",
        "    * Validation,\n",
        "6. Оценить качество итогового детектора.\n",
        "   * Используя COCO API посчитать mAP\n",
        "  \n",
        "И, для начала, поговорим о данных с которыми нам предстоит работать"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a31370d3-632b-41e1-9891-26d9681b6f05",
      "metadata": {
        "id": "a31370d3-632b-41e1-9891-26d9681b6f05"
      },
      "source": [
        "### Working with dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b2600e4-ac5d-4bd1-a486-23069891d97e",
      "metadata": {
        "id": "7b2600e4-ac5d-4bd1-a486-23069891d97e"
      },
      "outputs": [],
      "source": [
        "# Определяем константы для цвета и названий классов\n",
        "class_to_color = {\n",
        "    1: (89, 161, 197),\n",
        "    2: (204, 79, 135),\n",
        "    3: (125, 216, 93),\n",
        "    4: (175, 203, 33),\n",
        "}\n",
        "\n",
        "class_to_name = {\n",
        "    1 : \"enemy\",\n",
        "    2 : \"enemy-head\",\n",
        "    3 : \"friendly\",\n",
        "    4 : \"friendly-head\"\n",
        "}\n",
        "\n",
        "splits = {'train': 'data/train-00000-of-00001-0d6632d599c29801.parquet',\n",
        "          'validation': 'data/validation-00000-of-00001-c6b77a557eeedd52.parquet',\n",
        "          'test': 'data/test-00000-of-00001-866d29d8989ea915.parquet'}\n",
        "df_train = pd.read_parquet(\"hf://datasets/Francesco/halo-infinite-angel-videogame/\" + splits[\"train\"])\n",
        "df_test = pd.read_parquet(\"hf://datasets/Francesco/halo-infinite-angel-videogame/\" + splits[\"test\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0ba7d3b-c563-4d30-a589-a33d729f9e03",
      "metadata": {
        "id": "c0ba7d3b-c563-4d30-a589-a33d729f9e03"
      },
      "source": [
        "Выведем пример данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "311cb055-99df-43c2-9c14-1debd2663d50",
      "metadata": {
        "id": "311cb055-99df-43c2-9c14-1debd2663d50"
      },
      "outputs": [],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9beb549c-d64f-410f-a4eb-4e84f3fb6e4f",
      "metadata": {
        "id": "9beb549c-d64f-410f-a4eb-4e84f3fb6e4f"
      },
      "outputs": [],
      "source": [
        "# Вспомогательные функции для отрисовки данных\n",
        "def add_bbox(image, box, label='', color=(128, 128, 128), txt_color=(0, 0, 0)):\n",
        "    lw = max(round(sum(image.shape) / 2 * 0.003), 2)\n",
        "    p1, p2 = (int(box[0]), int(box[1])), (int(box[0]) + int(box[2]), int(box[1]) + int(box[3]))\n",
        "    cv2.rectangle(image, p1, p2, color, thickness=lw, lineType=cv2.LINE_AA)\n",
        "    if label:\n",
        "        tf = max(lw - 1, 1)\n",
        "        w, h = cv2.getTextSize(label, 0, fontScale=lw / 3, thickness=tf)[0]\n",
        "        outside = p1[1] - h >= 3\n",
        "        p2 = p1[0] + w, p1[1] - h - 3 if outside else p1[1] + h + 3\n",
        "        cv2.rectangle(image, p1, p2, color, -1, cv2.LINE_AA)\n",
        "        cv2.putText(image,\n",
        "                    label, (p1[0], p1[1] - 2 if outside else p1[1] + h + 2),\n",
        "                    0,\n",
        "                    lw / 3,\n",
        "                    txt_color,\n",
        "                    thickness=tf,\n",
        "                    lineType=cv2.LINE_AA)\n",
        "    return image\n",
        "\n",
        "def plot_examples(df, indices=None, num_examples=6, row_figsize=(12, 3)):\n",
        "    if indices is None:\n",
        "        indices = np.random.choice(len(df), size=num_examples, replace=False)\n",
        "    else:\n",
        "        num_examples = len(indices)\n",
        "    ncols = min(num_examples, 3)\n",
        "    nrows = math.ceil(num_examples / 3)\n",
        "    _, axes = plt.subplots(nrows, ncols, figsize=(row_figsize[0], row_figsize[1] * nrows), tight_layout=True)\n",
        "    axes = axes.reshape(-1)\n",
        "    for ix, ax in zip(indices, axes):\n",
        "        row = df.iloc[ix]\n",
        "        image = Image.open(io.BytesIO(row['image']['bytes']))\n",
        "        bboxes = row[\"objects\"]['bbox']\n",
        "        classes = row[\"objects\"]['category']\n",
        "        img = np.array(image)\n",
        "        for bbox, label in zip(bboxes, classes):\n",
        "            color = class_to_color[label]\n",
        "            class_name = class_to_name[label]\n",
        "            img = add_bbox(img, bbox, label=str(class_name), color=color)\n",
        "        ax.imshow(img)\n",
        "        ax.set_title(f\"Image id: {row['image_id']}\")\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89c5df93-edf9-4456-9b5e-7c0621c889c8",
      "metadata": {
        "id": "89c5df93-edf9-4456-9b5e-7c0621c889c8"
      },
      "source": [
        "Нарисуем несколько примеров картинок из обучающей выборки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc9a2fdf-5500-433a-9018-9ac2c3211eef",
      "metadata": {
        "id": "fc9a2fdf-5500-433a-9018-9ac2c3211eef"
      },
      "outputs": [],
      "source": [
        "plot_examples(df_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc7fcded-4093-45e5-bf6e-cd14b59f4002",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-06T19:12:38.634502Z",
          "iopub.status.busy": "2025-03-06T19:12:38.633796Z",
          "iopub.status.idle": "2025-03-06T19:12:38.641240Z",
          "shell.execute_reply": "2025-03-06T19:12:38.640130Z",
          "shell.execute_reply.started": "2025-03-06T19:12:38.634423Z"
        },
        "id": "bc7fcded-4093-45e5-bf6e-cd14b59f4002"
      },
      "source": [
        "Нарисуем несколько примеров картинок из тестовой выборки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8beb9847-0f8d-435e-a6df-474f3e9407d1",
      "metadata": {
        "id": "8beb9847-0f8d-435e-a6df-474f3e9407d1"
      },
      "outputs": [],
      "source": [
        "plot_examples(df_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e7c636b-cff8-4bc6-83d0-53af094f706b",
      "metadata": {
        "id": "7e7c636b-cff8-4bc6-83d0-53af094f706b"
      },
      "source": [
        "Посчитаем количество данных в двух датасетах"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36a961b8-60b0-46fb-b075-5c2b12597561",
      "metadata": {
        "id": "36a961b8-60b0-46fb-b075-5c2b12597561"
      },
      "outputs": [],
      "source": [
        "print(f\"Train length: {len(df_train)}\\nTest length: {len(df_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2463ba65-ad0e-4602-96d4-dda2082122cc",
      "metadata": {
        "id": "2463ba65-ad0e-4602-96d4-dda2082122cc"
      },
      "source": [
        "Посмотрим на некоторые статистики по датасету"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "690a47da-b4c5-41d7-bb99-7452772f89a5",
      "metadata": {
        "id": "690a47da-b4c5-41d7-bb99-7452772f89a5"
      },
      "outputs": [],
      "source": [
        "def part_info(df):\n",
        "    \"\"\" Считаем статистики по датасету и рисуем распределение размеров ббоксов по классам. \"\"\"\n",
        "    df = pd.json_normalize(df['objects'])[[\"bbox\", \"category\"]]\n",
        "    obj_per_img = df['bbox'].apply(lambda obj: len(obj))\n",
        "    print(f\"Min bboxes per image: {obj_per_img.min()}\")\n",
        "    print(f\"Max bboxes per image: {obj_per_img.max()}\")\n",
        "    print(f\"Mean bboxes per image: {obj_per_img.mean():.3}\")\n",
        "\n",
        "    all_categories = df['category'].apply(lambda obj: obj).tolist()\n",
        "    counter = Counter(np.concatenate(all_categories))\n",
        "    msg = [f\"{class_to_name[key]} : {value}\" for key, value in counter.items()]\n",
        "    print(\"\\n\\nNumber of object per class:\\n\" + \"\\n\".join(msg))\n",
        "\n",
        "    bboxes = defaultdict(list)\n",
        "    for _, row in df.iterrows():\n",
        "        for bb, cls in zip(row['bbox'], row['category']):\n",
        "            bboxes[cls].append(list(bb[2:]))\n",
        "    bboxes = dict(sorted(bboxes.items()))\n",
        "    print(\"\\nMean bbox size per class:\")\n",
        "    for cls, boxes_list in bboxes.items():\n",
        "        print(f\"{class_to_name[cls]} : {np.mean(boxes_list, axis=0)}\")\n",
        "\n",
        "    print(\"\\n\\n\")\n",
        "    _, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "    x_boxes = [np.array(val)[:, 0] for val in bboxes.values()]\n",
        "    y_boxes = [np.array(val)[:, 1] for val in bboxes.values()]\n",
        "    labels = [class_to_name[cls] for cls in class_to_name.keys()]\n",
        "    colors = [class_to_color[cls] for cls in class_to_color.keys()]\n",
        "    for ax, box, direction in zip(axes, [x_boxes, y_boxes], [\"width\", \"hight\"]):\n",
        "        bplot = ax.boxplot(box, patch_artist=True, tick_labels=labels)\n",
        "        for patch, color in zip(bplot[\"boxes\"], colors):\n",
        "            patch.set_facecolor(np.array(color) / 255)\n",
        "        ax.set_ylabel(f\"Bbox size by {direction}\")\n",
        "        ax.set_title(f\"Bboxes distribution per class by {direction}\")\n",
        "\n",
        "box_sizes = part_info(df_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fed0c88-b19c-484f-a33b-25db6d9318e4",
      "metadata": {
        "id": "3fed0c88-b19c-484f-a33b-25db6d9318e4"
      },
      "outputs": [],
      "source": [
        "box_sizes = part_info(df_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56c24b78-65d3-407f-8db2-c5efc6409353",
      "metadata": {
        "id": "56c24b78-65d3-407f-8db2-c5efc6409353"
      },
      "source": [
        "Справка про boxplot из [matplotlib](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.boxplot.html):\n",
        "\n",
        "\n",
        "![image.png](attachment:5e15ffae-9959-4dc3-a4a8-5d45d5efe7f9.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "601aa537-b043-4d10-bdc0-44ac2b23d824",
      "metadata": {
        "id": "601aa537-b043-4d10-bdc0-44ac2b23d824"
      },
      "source": [
        "Отлично, на данные посмотрели, теперь давайте напишем Dataset, с помощью которого будем загружать данные."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d528e2f0-9867-42ef-a3ac-e14acf73b8cc",
      "metadata": {
        "id": "d528e2f0-9867-42ef-a3ac-e14acf73b8cc"
      },
      "outputs": [],
      "source": [
        "class HaloDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        df_objects = pd.json_normalize(dataframe['objects'])[[\"bbox\", \"category\"]]\n",
        "        df_images = pd.json_normalize(dataframe['image'])[[\"bytes\"]]\n",
        "        self.data = dataframe[[\"image_id\"]].join(df_objects).join(df_images)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Загружаем данные и разметку для объекта с индексом `idx`.\n",
        "\n",
        "        labels: List[int] Набор классов для каждого ббокса,\n",
        "        boxes: List[List[int]] Набор ббоксов в формате (x_min, y_min, w, h).\n",
        "        \"\"\"\n",
        "        row = self.data.iloc[idx]\n",
        "        image = Image.open(io.BytesIO(row[\"bytes\"]))\n",
        "        image = np.array(image)\n",
        "\n",
        "        target = {}\n",
        "        target[\"image_id\"] = row[\"image_id\"]\n",
        "\n",
        "        labels = [row[\"category\"]] if isinstance(row[\"category\"], int) else row['category']\n",
        "        # Вычитаем единицу чтобы классы начинались с нуля\n",
        "        labels = [label - 1 for label in labels]\n",
        "        boxes = row['bbox'].tolist()\n",
        "\n",
        "        if self.transform is not None:\n",
        "            transformed = self.transform(image=image, bboxes=boxes, labels=labels)\n",
        "            image, boxes, labels = transformed[\"image\"], transformed[\"bboxes\"], transformed[\"labels\"]\n",
        "        else:\n",
        "            image = transforms.ToTensor()(image)\n",
        "\n",
        "        target['boxes'] = torch.tensor(np.array(boxes), dtype=torch.float32)\n",
        "        target['labels'] = torch.tensor(labels, dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch = tuple(zip(*batch))\n",
        "    images = torch.stack(batch[0])\n",
        "    return images, batch[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a53ae90-8dee-4e6b-8846-272b428c783d",
      "metadata": {
        "id": "8a53ae90-8dee-4e6b-8846-272b428c783d"
      },
      "outputs": [],
      "source": [
        "# Немного аугментаций\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "\n",
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.229, 0.224, 0.225)\n",
        "\n",
        "train_transform = A.Compose(\n",
        "    [\n",
        "        A.Normalize(mean=mean, std=std),\n",
        "        # HorizontalFlip меняет и ббоксы!\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.RandomBrightnessContrast(p=0.2),\n",
        "        ToTensorV2(),\n",
        "    ],\n",
        "    bbox_params=A.BboxParams(format='coco', label_fields=['labels'])\n",
        ")\n",
        "\n",
        "test_transform = A.Compose(\n",
        "    [\n",
        "        A.Normalize(mean=mean, std=std),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4c92817-cd32-4c70-97cc-bab4bc87297f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-06T15:18:25.818298Z",
          "iopub.status.busy": "2025-03-06T15:18:25.817055Z",
          "iopub.status.idle": "2025-03-06T15:18:25.863863Z",
          "shell.execute_reply": "2025-03-06T15:18:25.862763Z",
          "shell.execute_reply.started": "2025-03-06T15:18:25.818217Z"
        },
        "id": "d4c92817-cd32-4c70-97cc-bab4bc87297f"
      },
      "source": [
        "Создадим Dataset для наших данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2232a5b-0a18-4d77-8121-f1f257bbf4fa",
      "metadata": {
        "id": "d2232a5b-0a18-4d77-8121-f1f257bbf4fa"
      },
      "outputs": [],
      "source": [
        "train_dataset = HaloDataset(df_train, transform=train_transform)\n",
        "test_dataset = HaloDataset(df_test, transform=test_transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f80c2f79-70aa-4181-9bc9-70ed66495b12",
      "metadata": {
        "id": "f80c2f79-70aa-4181-9bc9-70ed66495b12"
      },
      "source": [
        "### On the Way to Object Detector\n",
        "\n",
        "Вспомним как выглядит общая структура модели:\n",
        "\n",
        "![Base detector schema full.png](attachment:1698d15c-c1e9-433c-90f0-0a1a4056e318.png)\n",
        "\n",
        "Мы будем реализовывать самый простой вариант object detector'a, чем то похожий на первые YOLO модели с использованием якорей.\n",
        "\n",
        "В качестве backbone можно использовать любую классификационную модель. Давайте выберем предобученную на ImageNet модель, и заморозим у неё все слои, чтобы нам было проще обучать модель.\n",
        "\n",
        "TIP: Можно разморозить несколько последних слоев и обучать их тоже, качество может стать лучше."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86c4a1c3-7396-4032-b8c7-aee1cdd10a2d",
      "metadata": {
        "id": "86c4a1c3-7396-4032-b8c7-aee1cdd10a2d"
      },
      "outputs": [],
      "source": [
        "class Backbone(nn.Module):\n",
        "    def __init__(self, model_name=\"efficientnet_b0\", out_indices=(-1, -2, -3)):\n",
        "        super().__init__()\n",
        "        # timm.list_models(pretrained=True)\n",
        "        self.backbone = timm.create_model(model_name, pretrained=True, features_only=True, out_indices=out_indices)\n",
        "        # Выключаем градиенты у модели, чтобы упростить обучение\n",
        "        for param in self.backbone.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c358623-35a1-4961-9ef2-ddd3003c19bc",
      "metadata": {
        "id": "4c358623-35a1-4961-9ef2-ddd3003c19bc"
      },
      "source": [
        "Теперь напишем два простых класса для шеи и головы нашего детектора.\n",
        "\n",
        "Для простоты будем реализовывать детектор с одним выходом, поэтому шея будет максимально простая."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10aa82fd-feb4-48d1-b3a0-128f4b027069",
      "metadata": {
        "id": "10aa82fd-feb4-48d1-b3a0-128f4b027069"
      },
      "outputs": [],
      "source": [
        "class SimplifiedFPN(nn.Module):\n",
        "    \"\"\"Очень простая шея: один слой conv + batch_norm + activation. \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, use_activations=True):\n",
        "        super().__init__()\n",
        "        self.fpn_conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.activation = nn.ReLU() if use_activations else nn.Identity()\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, features):\n",
        "        return self.activation(self.bn(self.fpn_conv(features[0])))\n",
        "\n",
        "\n",
        "class DetectionHead(nn.Module):\n",
        "    \"\"\" Двухсоставная голова, схематично выглядит следующим образом:\n",
        "                      -> conv (cls) [B, NUM_ANCHORS * NUM_CLASSES, W, H]\n",
        "        neck -> conv\n",
        "                      -> conv (reg) [B, NUM_ACNHORS * 5, W, H]\n",
        "    где число 5 обозначает 4 смещения для итогового + confidence score.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, num_anchors, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
        "        self.cls_head = nn.Conv2d(in_channels, num_anchors * num_classes, kernel_size=1)\n",
        "        self.reg_head = nn.Conv2d(in_channels, num_anchors * 5, kernel_size=1)\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv(x))\n",
        "        cls_logits = self.cls_head(x)\n",
        "        bbox_preds = self.reg_head(x)\n",
        "        return cls_logits, bbox_preds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be22b69d-081e-4b31-aa53-5061581ff352",
      "metadata": {
        "id": "be22b69d-081e-4b31-aa53-5061581ff352"
      },
      "source": [
        "Прежде чем собирать все вместе, давайте определимся что именно предсказывает наша сеть.\n",
        "\n",
        "Для примера, давайте предсказывать смещения, также как в YOLOv3:\n",
        "\n",
        "![image.png](attachment:da9209ed-3acc-499c-8992-36e1c7e8c09e.png), где\n",
        "\n",
        "* $c_x, c_y$ - растояние от верхнего левого угла до начала ячейки,\n",
        "* $p_w, p_h$ - размеры якоря,\n",
        "* $t_x, t_y, t_w, t_h$ - предсказания модели,\n",
        "* $b_x, b_y, b_w, b_h$ - итоговые размеры ббокса в формате YOLO.\n",
        "  * $b_x, b_y$ - координаты центра ббокса,\n",
        "  * $b_w, b_h$ - ширина, высота ббокса.\n",
        "\n",
        "Теперь можем собрать все вместе и также реализовать преобразования из смещений в ббоксы для всех предсказаний."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6cb3f7d-b1c1-4875-853b-537f0d59f6d8",
      "metadata": {
        "id": "d6cb3f7d-b1c1-4875-853b-537f0d59f6d8"
      },
      "outputs": [],
      "source": [
        "class Detector(nn.Module):\n",
        "    \"\"\" Класс детектора, объединяющий все части вместе.\n",
        "\n",
        "    Параметры\n",
        "    ---------\n",
        "    backbone_model_name : str\n",
        "        Имя timm модели, которая будет исопльзоваться в качестве backbone\n",
        "    neck_n_channels : int\n",
        "        Итоговое количество каналов на выходе шеи\n",
        "    num_classes : int\n",
        "        Количество классов в датасете\n",
        "    anchor_sizes : list, tuple\n",
        "        Базовые размеры якорей. Используется методом `AnchorDetector` из\n",
        "        `torchvision.models.detection.anchor_utils`для создания якорей.\n",
        "    anchor_ratios : list, tuple\n",
        "        Соотношения сторон якорей. Используется методом `AnchorDetector` из\n",
        "        `torchvision.models.detection.anchor_utils`для создания якорей.\n",
        "    input_size : tuple with length 2\n",
        "        Размер входного изображения. Используется для расчета положения всех якорей.\n",
        "\n",
        "    NOTE: На самом деле, AnchorDetector на вход ждет anchor_sizes и anchor_ratios как Tuple[Tuple[int]],\n",
        "    это связано с возможностью создания разных якорей для разных выходов модели. Сейчас нам это не нужно,\n",
        "    поэтому структура намеренно упрощена.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 backbone_model_name=\"efficientnet_b0\",\n",
        "                 neck_n_channels=256,\n",
        "                 num_classes=4,\n",
        "                 anchor_sizes=(32, 64, 128),\n",
        "                 anchor_ratios=(0.5, 1.0, 2.0),\n",
        "                 input_size=(640, 640),\n",
        "        ):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        # Создаем backbone с одним выходом, только из последнего слоя\n",
        "        # Если нужно сделать несколько выходов, меняй out_indices\n",
        "        self.backbone = Backbone(backbone_model_name, out_indices=(-1, ))\n",
        "        # Получаем количество фичемапов на выходном слое\n",
        "        in_channels = self.backbone.backbone.feature_info.channels()[0]\n",
        "        # Создаем шею, с учетом параметров, полученных выше\n",
        "        self.neck = SimplifiedFPN(in_channels, out_channels=neck_n_channels)\n",
        "        # Размерность выходов головы зависит от количество якорей, поэтому сначала считаем количество якорей в каждой\n",
        "        # ячейке выходной фичемапы\n",
        "        num_anchors = len(anchor_sizes) * len(anchor_ratios)\n",
        "        self.head = DetectionHead(in_channels=neck_n_channels, num_anchors=num_anchors, num_classes=num_classes)\n",
        "\n",
        "        # Генерируем якоря\n",
        "        anchor_generator = AnchorGenerator(sizes=(anchor_sizes, ), aspect_ratios=(anchor_ratios, ))\n",
        "        # Узнаем размер выходной фичемапы\n",
        "        reduction = self.backbone.backbone.feature_info.reduction()[0]\n",
        "        grid_sizes = [[input_size[0] // reduction, input_size[1] // reduction]]\n",
        "\n",
        "        # Расчитываем координаты якорей в каждой точке выходной фичемапы.\n",
        "        ###\n",
        "        # Якоря хранятся в формате (x_min, y_min, x_max, y_max)!\n",
        "        ###\n",
        "        anchors = anchor_generator.grid_anchors(grid_sizes, strides=[[reduction, reduction]])\n",
        "        anchors = torch.stack(anchors, dim=0)\n",
        "        # Заранее считаем координаты якорей в формате (x_center, y_center, w, h)\n",
        "        # Это пригодится для расчета лосса\n",
        "        anchor_centers = (anchors[:, :, :2] + anchors[:, :, 2:]) / 2\n",
        "        anchor_sizes = (anchors[:, :, 2:] - anchors[:, :, :2])\n",
        "\n",
        "        self.register_buffer(\"anchors\", anchors)\n",
        "        self.register_buffer(\"anchor_centers\", anchor_centers)\n",
        "        self.register_buffer(\"anchor_sizes\", anchor_sizes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Пропускаем картинку через всю сеть\n",
        "        features = self.backbone(x)\n",
        "        neck_features = self.neck(features)\n",
        "        cls_logits, bbox_preds = self.head(neck_features)\n",
        "\n",
        "        # Преобразуем сырые выходы модели в формат, в котором будет удобно считать лосс\n",
        "        # cls_logits - [N, NUM_ANCHORS * NUM_CLASSES, W, H]\n",
        "        # bbox_preds - [N, NUM_ANCHORS * 5, W, H]\n",
        "        N = x.shape[0]\n",
        "        cls_logits = cls_logits.permute(0, 2, 3, 1).contiguous()\n",
        "        cls_logits = cls_logits.view(N, -1, self.head.num_classes) # [N, NUM_ANCHORS * W * H, NUM_CLASSES]\n",
        "\n",
        "        bbox_preds = bbox_preds.permute(0, 2, 3, 1).contiguous()\n",
        "        bbox_preds = bbox_preds.view(N, -1, 5) # [N, NUM_ANCHORS * W * H, 5]\n",
        "        bbox_offsets = bbox_preds[:, :, :4]\n",
        "        confidence_logits = bbox_preds[:, :, 4]\n",
        "\n",
        "        if self.training:\n",
        "            # В процессе тренировки возвращаем просто смещения и логиты\n",
        "            return bbox_offsets, confidence_logits, cls_logits\n",
        "\n",
        "        # Если мы делаем предсказание, сразу считаем итоговый ббокс и вероятности\n",
        "        # Модель предсказывает ббоксы в формате (x_min, y_min, w, h)\n",
        "        bboxes = self.decode_bboxes(bbox_offsets)\n",
        "        confidence = torch.sigmoid(confidence_logits)\n",
        "        cls_probs = torch.softmax(cls_logits, dim=-1)\n",
        "        return bboxes, confidence, cls_probs\n",
        "\n",
        "\n",
        "    def decode_bboxes(self, bbox_offsets):\n",
        "        \"\"\"Используя предсказанные смещения, считаем предсказанные ббоксы по формулам из YOLOv3.\n",
        "\n",
        "        Боксы возвращаются в формате (x_min, y_min, w, h).\n",
        "        \"\"\"\n",
        "        tx = bbox_offsets[:, :, 0]\n",
        "        ty = bbox_offsets[:, :, 1]\n",
        "        tw = bbox_offsets[:, :, 2]\n",
        "        th = bbox_offsets[:, :, 3]\n",
        "\n",
        "        center_x = self.anchor_centers[:, :, 0] + torch.sigmoid(tx) * self.anchor_sizes[:, :, 0]\n",
        "        center_y = self.anchor_centers[:, :, 1] + torch.sigmoid(ty) * self.anchor_sizes[:, :, 1]\n",
        "\n",
        "        w = torch.exp(tw) * self.anchor_sizes[:, :, 0]\n",
        "        h = torch.exp(th) * self.anchor_sizes[:, :, 1]\n",
        "\n",
        "        x_min = center_x - w / 2\n",
        "        y_min = center_y - h / 2\n",
        "        return torch.stack([x_min, y_min, w, h], dim=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "733e290c-1de5-452c-95f1-60703dd6da4d",
      "metadata": {
        "id": "733e290c-1de5-452c-95f1-60703dd6da4d"
      },
      "source": [
        "### Training\n",
        "\n",
        "Настало время обучить нашу модель. Общая формула лоссы выглядит следующим образом:\n",
        "$$ L = \\lambda_{loc} L_{loc} + \\lambda_{conf} L_{conf} + \\lambda_{cls} L_{cls} \\text{ , где}$$\n",
        "$L_{offset}$ - Локализационная часть лосса,\n",
        "\n",
        "$L_{conf}$ - Confidence лосс,\n",
        "\n",
        "$L_{cls}$ - Классификационная часть лосса,\n",
        "\n",
        "$\\lambda_{loc}, \\lambda_{conf}, \\lambda_{cls}$ - Балансировочные константы\n",
        "\n",
        "Локализационный лосс обычно вычисляется одним из двух способов:\n",
        "1. Использование лоссов, основанных на расстояниях (SmoothL1 и тд)\n",
        "2. Использование лоссов, основанных на пересеченнии ббоксов (IoU-based лоссы)\n",
        "\n",
        "Для каждого из подходов нужны разные пары (предсказаные, таргет):\n",
        "1. **Предсказания** - смещения (сырые предсказания из сети), **таргет** - истинные смещения (их нужно посчитать для каждого якоря самостоятельно).\n",
        "\n",
        "    Приведем пример для нашего варианта:\n",
        "   $$ t_x = logit \\left[\\frac{x_{gt} - x_{anchor}}{w_{anchor}}\\right], t_y = logit \\left[\\frac{y_{gt} - y_{anchor}}{h_{anchor}}\\right] $$\n",
        "   $$ t_w = \\log\\frac{w_{gt}}{w_{anchor}}, t_h = \\log\\frac{h_{gt}}{h_{anchor}} $$, где\n",
        "   * $x_{gt}, x_{anchor}, y_{gt}, y_{anchor}$ - координаты цетра GT и якоря,\n",
        "   * $w_{gt}, w_{anchor}, h_{gt}, h_{anchor}$ - размеры GT и якоря.\n",
        "3. **Предсказания** - ббокс (смещения примененные к якорям), **таргет** - истинные ббоксы без изменений.\n",
        "\n",
        "Второй вариант используется чаще в современных архитектурах. Давайте для разнообразия реализуем первый вариант, с пересчетом таргета в смещения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f941c0c7-1ec6-4da6-a672-e8b99a8cffd7",
      "metadata": {
        "id": "f941c0c7-1ec6-4da6-a672-e8b99a8cffd7"
      },
      "outputs": [],
      "source": [
        "def safe_logit(x):\n",
        "    \"\"\" Безопасный расчет logit'ов. \"\"\"\n",
        "    eps = 1e-6\n",
        "    x = torch.clamp(x, eps, 1 - eps)\n",
        "    return torch.log(x / (1 - x))\n",
        "\n",
        "def get_target_offset(anchor_box, gt_box):\n",
        "    \"\"\" Расчитываем таргет как желаемые смещения от якорей до GT.\n",
        "\n",
        "    anchor_box: torch.Tensor в формате (x_min, y_min, x_max, y_max),\n",
        "    gt_box: torch.Tensor в формате (x_min, y_min, x_max, y_max).\n",
        "    \"\"\"\n",
        "    # Конвертируем GT в формат (x_center, y_center), (w, h)\n",
        "    gt_center = (gt_box[:2] + gt_box[2:]) / 2\n",
        "    gt_size = gt_box[2:] - gt_box[:2]\n",
        "\n",
        "    # Конвертируем якоря в формат (x_center, y_center), (w, h)\n",
        "    anchor_center = (anchor_box[:2] + anchor_box[2:]) / 2\n",
        "    anchor_size = anchor_box[2:] - anchor_box[:2]\n",
        "\n",
        "    # Вычисляем значения смещений для положительных ббоксов\n",
        "    tx = (gt_center[0] - anchor_center[0]) / anchor_size[0]\n",
        "    ty = (gt_center[1] - anchor_center[1]) / anchor_size[1]\n",
        "    target_tx = safe_logit(tx)\n",
        "    target_ty = safe_logit(ty)\n",
        "\n",
        "    target_tw = torch.log(gt_size[0] / anchor_size[0])\n",
        "    target_th = torch.log(gt_size[1] / anchor_size[1])\n",
        "    return torch.tensor([target_tx, target_ty, target_tw, target_th]).to(anchor_box.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b9f1dc7-0c68-4488-910d-4933ab1ab92f",
      "metadata": {
        "id": "1b9f1dc7-0c68-4488-910d-4933ab1ab92f"
      },
      "source": [
        "Теперь мы знаем как считать итоговые предсказания. Следующим шагом давайте реализуем весь процесс сопоставления таргетов и якорей (label assignment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40a687cc-9ecf-46f1-be73-f620f1424bed",
      "metadata": {
        "id": "40a687cc-9ecf-46f1-be73-f620f1424bed"
      },
      "outputs": [],
      "source": [
        "def assign_target(anchors, gt_boxes, gt_labels, num_classes, pos_th=0.6, neg_th=0.3):\n",
        "    \"\"\" Для каждого GT находим якоря, которые будут участвовать в расчете лосса по следующему алгоритму:\n",
        "    1. Положительные якоря - якоря у которых IoU с GT >= `pos_th`,\n",
        "    2. Игнорируемые якоря - `neg_th` <= IoU c GT < `pos_th`,\n",
        "    3. Отрицательные якоря - IoU c GT < `neg_th`.\n",
        "    4. Если для GT не нашлось ни одного якоря, назначаем GT якорь с самым большим IoU.\n",
        "\n",
        "    Параметры\n",
        "    ---------\n",
        "    anchors : list[list[float]]\n",
        "        Набор якорей для выходной фичемапы, размер (NUM_ANCHORS * W * H, 4)\n",
        "    gt_boxes : list[list[float]]\n",
        "        Набор истинных ббоксов на изображении, размер (N_GT, 4)\n",
        "    gt_labels : list[int]\n",
        "        Набор лейблов для GT, размер (N_GT, )\n",
        "    num_classes : int\n",
        "        Количество классов в датасете\n",
        "    pos_th : float\n",
        "        Минимальная граница по IoU между якорем и GT после которой якорь считается положительным.\n",
        "    neg_th : float\n",
        "        Верхняя граница по IoU между якорем и GT когда якорь считается отрицательным.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    target_offsets: Массив, содержащий истинные смещения для положительных якорей, 0 для всех остальных\n",
        "    target_objectness: Массив, содержащий тип каждого якоря (1 - положительный, 0 - отрицательный, -1 - игнорируемый)\n",
        "    target_cls: Массив, содержащий ohe классы для каждого якоря. Для всех, кроме положительных якорей, класс не указан.\n",
        "    \"\"\"\n",
        "    num_anchors = anchors.shape[0]\n",
        "    target_objectness = torch.zeros(num_anchors, device=anchors.device)\n",
        "    target_offsets = torch.zeros((num_anchors, 4), device=anchors.device)\n",
        "    target_cls = torch.zeros((num_anchors, num_classes), device=anchors.device)\n",
        "    # Если на изображении нет объектов, возвращаем пустые списки\n",
        "    if gt_boxes.numel() == 0:\n",
        "        return target_offsets, target_objectness, target_cls\n",
        "    # box_iou работает с форматом ббоксов (x_min, y_min, x_max, y_max)\n",
        "    # Якоря находятся в нужном формате, а GT - нет, тк имеет формат (x_min, y_min, w, h)\n",
        "    # Переведем GT боксы в нужный формат\n",
        "    gt_xyxy = gt_boxes.clone()\n",
        "    gt_xyxy[:, 2:] = gt_xyxy[:, :2] + gt_xyxy[:, 2:]\n",
        "    # Считаем iou между всеми якорями и всеми GT\n",
        "    ious = box_iou(anchors, gt_xyxy) # [num_anchors, num_gt]\n",
        "    # Находим самый оптимальный GT для каждого якоря\n",
        "    best_iou, best_gt_idx = ious.max(dim=1)\n",
        "    # Отмечаем якоря, которые будут пропущены при расчете лосса\n",
        "    ignore_mask = (best_iou >= neg_th) & (best_iou < pos_th)\n",
        "    target_objectness[ignore_mask] = -1\n",
        "\n",
        "    # Отмечаем якоря, для которых будет считаться локализационный лосс\n",
        "    pos_mask = best_iou >= pos_th\n",
        "    pos_indices = pos_mask.nonzero(as_tuple=True)[0]\n",
        "    for pos in pos_indices:\n",
        "        gt_idx = best_gt_idx[pos]\n",
        "        gt_box = gt_xyxy[gt_idx]\n",
        "        anchor_box = anchors[pos]\n",
        "\n",
        "        target_offsets[pos] = get_target_offset(anchor_box, gt_box)\n",
        "        target_objectness[pos] = 1\n",
        "        target_cls[pos, gt_labels[gt_idx]] = 1\n",
        "\n",
        "    # Присваиваем предсказание с самым большим IoU для GT\n",
        "    # у которых не нашлось ни оного предсказания\n",
        "    for gt_idx in range(gt_xyxy.shape[0]):\n",
        "        if not((target_objectness == 1) & (best_gt_idx == gt_idx)).any():\n",
        "            best_anchor_idx = torch.argmax(ious[:, gt_idx])\n",
        "            target_offsets[best_anchor_idx] = get_target_offset(anchors[best_anchor_idx], gt_xyxy[gt_idx])\n",
        "            target_objectness[best_anchor_idx] = 1\n",
        "            target_cls[best_anchor_idx, gt_labels[gt_idx]] = 1\n",
        "    return target_offsets, target_objectness, target_cls"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17a04ece-118f-45c7-b46c-0b66813fdf96",
      "metadata": {
        "id": "17a04ece-118f-45c7-b46c-0b66813fdf96"
      },
      "source": [
        "Теперь мы умеем сопоставлять якоря и GT, настало время задать лосс. Реализовывать его будем как класс с методом \\_\\_call__, который будет отвечать за расчет лосса."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2de0608e-30f9-4a4c-b3d4-1e1d20e77e2f",
      "metadata": {
        "id": "2de0608e-30f9-4a4c-b3d4-1e1d20e77e2f"
      },
      "outputs": [],
      "source": [
        "class ComputeLoss:\n",
        "    \"\"\" Базовый расчет лосса.\n",
        "\n",
        "    Параметры\n",
        "    ---------\n",
        "    bbox_loss : Локализационная часть лосса\n",
        "    obj_loss : Лосс для Confidence score\n",
        "    cls_loss : Классификационная часть лосса\n",
        "    weight_bbox, weight_obj, weight_cls : Константы для баллансировки частей лосса\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "            bbox_loss=None, obj_loss=None, cls_loss=None,\n",
        "            weight_bbox=5, weight_obj=1, weight_cls=1\n",
        "        ):\n",
        "        self.bbox_loss = nn.SmoothL1Loss() if bbox_loss is None else bbox_loss\n",
        "        self.obj_loss = nn.BCEWithLogitsLoss() if obj_loss is None else obj_loss\n",
        "        self.cls_loss = nn.BCEWithLogitsLoss() if cls_loss is None else cls_loss\n",
        "        self.weight_bbox = weight_bbox\n",
        "        self.weight_obj = weight_obj\n",
        "        self.weight_cls = weight_cls\n",
        "\n",
        "    def __call__(self, predicts, targets):\n",
        "        \"\"\" Расчет лосса для пары (предсказание, таргет)\n",
        "\n",
        "        Параметры\n",
        "        ---------\n",
        "        predicts : Предсказания модели для одной картинки: Смещения, objectness score и логиты для классов\n",
        "        targets : Gt значения для расчета лосса, а именно: GT смещения, GT objectness score и GT ohe классы\n",
        "        \"\"\"\n",
        "        pred_offsets, pred_obj_logits, pred_cls_logits = predicts\n",
        "        target_boxes, target_obj, target_cls = targets\n",
        "        # Confidence score считается только для предсказаний соотв отрицательным и положительным якорям\n",
        "        valid_mask = target_obj != -1\n",
        "        loss_obj = self.obj_loss(pred_obj_logits[valid_mask], target_obj[valid_mask])\n",
        "\n",
        "        # Локализационная и классификационные части считаются для предсказаинй соотв положительным якорям\n",
        "        pos_mask = target_obj == 1\n",
        "        if pos_mask.sum() > 0:\n",
        "            loss_cls = self.cls_loss(pred_cls_logits[pos_mask], target_cls[pos_mask])\n",
        "            loss_bbox = self.bbox_loss(pred_offsets[pos_mask], target_boxes[pos_mask])\n",
        "        else:\n",
        "            loss_cls = torch.tensor(0.0, device=pred_offsets.device)\n",
        "            loss_bbox = torch.tensor(0.0, device=pred_offsets.device)\n",
        "        return self.weight_bbox * loss_bbox + self.weight_obj * loss_obj + self.weight_cls * loss_cls"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2080d85f-5465-46d1-aea5-f7658ddc7c69",
      "metadata": {
        "id": "2080d85f-5465-46d1-aea5-f7658ddc7c69"
      },
      "source": [
        "Теперь можем реализовать класс для обучения и валидации нашей модели. Постараемся сделать его достаточно общим, чтобы можно было эксперементировать с различными моделями и методами присвоения якорей и тд."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f180de7-1c2f-4320-9308-8b35ef7f0eb2",
      "metadata": {
        "scrolled": true,
        "id": "1f180de7-1c2f-4320-9308-8b35ef7f0eb2"
      },
      "outputs": [],
      "source": [
        "class Runner:\n",
        "    \"\"\" Базовый класс для обучения и валидации модели.\n",
        "\n",
        "    Параметры\n",
        "    ---------\n",
        "    model : torch модель, которая будет обучаться.\n",
        "    compute_loss : экземпляр класса ComputeLoss (или другого с реализованным методом __call__).\n",
        "    optimizer : torch optimizer\n",
        "    train_dataloader : torch dataloader семплирующий данные для обучения модели.\n",
        "    assign_target_method : callable, который решает задачу сопоставления якорей и таргета (например, assign_target)\n",
        "    deivce : девайс на котором будет происходить обучения, по дефолту \"cpu\"\n",
        "    scheduler : torch scheduler\n",
        "    assign_target_kwargs : доп параметры для функции в `assign_target_method`,\n",
        "    val_dataloader : torch dataloader загружающий валидационные данные.\n",
        "    score_threshold : При расчете метрики на валидации, все предсказания,\n",
        "        с (confidence score * cls_probs) < score_threshold будут проигнорированны.\n",
        "    nms_threshold : Предсказания, имеющие пересечение по IoU >= nms_threshold будут считаться одним предсказанием.\n",
        "    max_boxes_per_cls : Максимальное количество ббоксов на изображение для одного класса после фильтрации по `score_threshold`.\n",
        "    \"\"\"\n",
        "    def __init__(self, model, compute_loss, optimizer, train_dataloader, assign_target_method, device=None,\n",
        "                 scheduler=None, assign_target_kwargs=None,\n",
        "                 val_dataloader=None, val_every=5, score_threshold=0.1, nms_threshold=0.5, max_boxes_per_cls=8):\n",
        "        self.model = model\n",
        "        self.compute_loss = compute_loss\n",
        "        self.optimizer = optimizer\n",
        "        self.train_dataloader = train_dataloader\n",
        "        assign_target_kwargs = {} if assign_target_kwargs is None else assign_target_kwargs\n",
        "        self.assign_target_method = partial(assign_target_method, **assign_target_kwargs)\n",
        "        self.device = \"cpu\" if device is None else device\n",
        "        self.scheduler = scheduler\n",
        "\n",
        "        # Валидационные параметры\n",
        "        self.val_dataloader = val_dataloader\n",
        "        self.val_every = val_every\n",
        "        self.score_threshold = score_threshold\n",
        "        self.nms_threshold = nms_threshold\n",
        "        self.max_boxes_per_cls = max_boxes_per_cls\n",
        "\n",
        "        # Вспомогательные массивы\n",
        "        self.batch_loss = []\n",
        "        self.epoch_loss = []\n",
        "        self.val_metric = []\n",
        "\n",
        "    def _run_train_epoch(self, dataloader, verbose=True):\n",
        "        \"\"\" Обучить модель одну эпоху на данных из `dataloader` \"\"\"\n",
        "        self.model.train()\n",
        "        batch_loss = []\n",
        "        for images, targets in (pbar := tqdm(dataloader, desc=f\"Process train epoch\", leave=False)):\n",
        "            images = images.to(self.device)\n",
        "            outputs = self.model(images)\n",
        "\n",
        "            anchors = self.model.anchors.view(-1, 4)\n",
        "            accum_loss = 0.0\n",
        "            for ix in range(images.shape[0]):\n",
        "                gt_boxes = targets[ix]['boxes'].to(self.device)\n",
        "                gt_labels = targets[ix]['labels'].to(self.device)\n",
        "                # выбираем какие якоря будут использоваться при расчете лосса.\n",
        "                assigned_targets = self.assign_target_method(anchors, gt_boxes, gt_labels,\n",
        "                                                             num_classes=model.num_classes)\n",
        "                # Считаем лосс на основании предсказаний модели и таргетов.\n",
        "                outputs_ixs = [out[ix] for out in outputs]\n",
        "                loss = self.compute_loss(outputs_ixs, assigned_targets)\n",
        "                accum_loss += loss\n",
        "            accum_loss = accum_loss / images.shape[0]\n",
        "            batch_loss.append(accum_loss.cpu().detach().item())\n",
        "\n",
        "            # Делаем шаг оптимизатора после расчета лосса для всех элементов батча\n",
        "            self.optimizer.zero_grad()\n",
        "            accum_loss.backward()\n",
        "            self.optimizer.step()\n",
        "        # Обновляем описание tqdm бара усредненным значением лосса за предыдущй батч\n",
        "            if verbose:\n",
        "                pbar.set_description(f\"Current batch loss: {batch_loss[-1]:.4}\")\n",
        "        return batch_loss\n",
        "\n",
        "    def train(self, num_epochs=10, verbose=True):\n",
        "        \"\"\" Обучаем модель заданное количество эпох. \"\"\"\n",
        "        val_desc = \"\"\n",
        "        for epoch in (epoch_pbar := tqdm(range(1, num_epochs+1), desc=\"Train epoch\", total=num_epochs)):\n",
        "            # Обучаем модель одну эпоху\n",
        "            loss = self._run_train_epoch(self.train_dataloader, verbose=verbose)\n",
        "            self.batch_loss.extend(loss)\n",
        "            self.epoch_loss.append(np.mean(self.batch_loss[-len(self.train_dataloader):]))\n",
        "\n",
        "            # Делаем валидацию, если был передан валидационный датасет\n",
        "            if self.val_dataloader is not None and epoch % self.val_every == 0:\n",
        "                val_metric = self.validate()\n",
        "                self.val_metric.append(val_metric)\n",
        "                val_desc = f\" Val {val_metric:.4}\"\n",
        "\n",
        "            # Обновляем описание tqdm бара усредненным значением лосса за предыдую эпоху\n",
        "            if verbose:\n",
        "                epoch_pbar.set_description(f\"Last epoch loss: Train {self.epoch_loss[-1]:.4}\" + val_desc)\n",
        "            # Делаем шаг scheduler'a если он был передан\n",
        "            if self.scheduler is not None:\n",
        "                self.scheduler.step()\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def validate(self, dataloader=None):\n",
        "        \"\"\" Метод для валидации модели. Если dataloader не передан, будет использоваться self.val_dataloder.\n",
        "        Возвращает mAP (0.5 ... 0.95).\n",
        "        \"\"\"\n",
        "        self.model.eval()\n",
        "        dataloader = self.val_dataloader if dataloader is None else dataloader\n",
        "        # Считаем метрику mAP с помощью функции из torchmetrics\n",
        "        metric = MeanAveragePrecision(box_format=\"xywh\", iou_type=\"bbox\")\n",
        "        for images, targets in tqdm(dataloader, desc=\"Running validation\", leave=False):\n",
        "            images = images.to(self.device)\n",
        "            outputs = self.model(images)\n",
        "            predicts = _filter_predictions(outputs, self.score_threshold, self.nms_threshold,\n",
        "                                           max_boxes_per_cls=self.max_boxes_per_cls, return_type=\"torch\")\n",
        "            metric.update(predicts, targets)\n",
        "        return metric.compute()[\"map\"].item()\n",
        "\n",
        "    def plot_loss(self, row_figsize=3):\n",
        "        nrows = 2 if self.val_metric else 1\n",
        "        _, ax = plt.subplots(nrows, 1, figsize=(12, row_figsize*nrows), tight_layout=True)\n",
        "        ax = np.array([ax]) if not isinstance(ax, np.ndarray) else ax\n",
        "        ax[0].plot(self.batch_loss, label=\"Train batch Loss\", color=\"tab:blue\")\n",
        "        ax[0].plot(np.arange(1, len(self.batch_loss)+1, len(self.train_dataloader)), self.epoch_loss,\n",
        "                   color=\"tab:orange\", label=\"Train epoch Loss\")\n",
        "        ax[0].grid()\n",
        "        ax[0].set_title(\"Train Loss\")\n",
        "        ax[0].set_xlabel(\"Number of Iterations\")\n",
        "        ax[0].set_ylabel(\"Loss\")\n",
        "        if self.val_metric:\n",
        "            ax[1].plot(np.arange(self.val_every, len(self.batch_loss)+1, len(self.val_dataloader) * self.val_every),\n",
        "                       np.array(self.val_metric) * 100, color=\"tab:green\", label=\"Validation mAP\")\n",
        "            ax[1].grid()\n",
        "            ax[1].set_title(\"Valiation mAP\")\n",
        "            ax[1].set_xlabel(\"Number of Iterations\")\n",
        "            ax[1].set_ylabel(\"mAP (%)\")\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "def _filter_predictions(predictions, score_threshold=0.1, nms_threshold=0.5, max_boxes_per_cls=8, return_type=\"list\"):\n",
        "    \"\"\" Ббоксы в `predictions` должны быть в формате (x_min, y_min, w, h). \"\"\"\n",
        "    # Итоговый скор считается как произведение уверенности модели в том что в данном якоре\n",
        "    # и вероятность каждого класса в данном якоре.\n",
        "    bboxes, confidences, cls_probs = predictions\n",
        "    all_final_scores = confidences[:, :, None] * cls_probs\n",
        "\n",
        "    num_classes = cls_probs.shape[-1]\n",
        "    final_predictions = []\n",
        "    # Для каждого элемента в `predictions` независимо выбираем ббоксы и скоры\n",
        "    for boxes, final_scores in zip(bboxes, all_final_scores):\n",
        "        preds = {\"boxes\": [], \"labels\": [], \"scores\": []}\n",
        "\n",
        "        # Для каждого класса отдельно фильтруем ббоксы с помощью NMS\n",
        "        for cls in range(num_classes):\n",
        "            cls_scores = final_scores[:, cls]\n",
        "            # Фильтруем ббоксы, score которых меньше порога\n",
        "            keep_ixs = cls_scores > score_threshold\n",
        "            if keep_ixs.sum() == 0:\n",
        "                continue\n",
        "            cls_boxes = boxes[keep_ixs]\n",
        "            cls_scores = cls_scores[keep_ixs]\n",
        "\n",
        "            # Если предсказаний слишком много, выбираем только самые уверенные\n",
        "            if len(cls_boxes) > max_boxes_per_cls:\n",
        "                pos = torch.argsort(cls_scores, descending=True)\n",
        "                cls_boxes = cls_boxes[pos[:max_boxes_per_cls]]\n",
        "                cls_scores = cls_scores[pos[:max_boxes_per_cls]]\n",
        "\n",
        "            # Конвертируем ббоксы в формат x_min, y_min, x_max, y_max\n",
        "            boxes_xyxy = cls_boxes.clone()\n",
        "            boxes_xyxy[:, 2:] = boxes_xyxy[:, :2] + boxes_xyxy[:, 2:]\n",
        "            # Запускаем NMS по всем оставшимся ббоксам класса cls\n",
        "            pred_ixs = nms(boxes_xyxy, cls_scores, nms_threshold)\n",
        "            # Сохраняем все предсказания для класса cls\n",
        "            for ix in pred_ixs:\n",
        "                preds[\"boxes\"].append(cls_boxes[ix].cpu().tolist())\n",
        "                preds[\"labels\"].append(cls)\n",
        "                preds[\"scores\"].append(cls_scores[ix].item())\n",
        "        if return_type == \"torch\":\n",
        "            for key, item in preds.items():\n",
        "                preds[key] = torch.tensor(item)\n",
        "        elif return_type != \"list\":\n",
        "            raise ValueError(f\"Received unexpected `return_type`. Could be either `torch` or `list`, not {return_type}\")\n",
        "        final_predictions.append(preds)\n",
        "    return final_predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eeda315c-33ab-4e24-a06c-2c3da13c8e53",
      "metadata": {
        "id": "eeda315c-33ab-4e24-a06c-2c3da13c8e53"
      },
      "source": [
        "Наконец то можно обучить нашу модель, давайте создадим `Runner` и обучим наш детектор."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec92989d-9f55-44f0-83d1-f39d3c991ae0",
      "metadata": {
        "id": "ec92989d-9f55-44f0-83d1-f39d3c991ae0"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=9, shuffle=False, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cad9155c-29e6-44ac-811b-da2ac98cd88e",
      "metadata": {
        "scrolled": true,
        "id": "cad9155c-29e6-44ac-811b-da2ac98cd88e"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "lr = 1e-3\n",
        "\n",
        "model = Detector(\"resnetv2_101\", num_classes=4, anchor_sizes=(30, 50, 140, 300), anchor_ratios=(0.5, 1, 1.6, 2)).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=5e-5)\n",
        "\n",
        "smooth_l1_loss = nn.SmoothL1Loss()\n",
        "bce_loss = nn.BCEWithLogitsLoss()\n",
        "compute_loss = ComputeLoss(smooth_l1_loss, bce_loss, bce_loss, weight_bbox=10)\n",
        "\n",
        "runner = Runner(model, compute_loss, optimizer, train_dataloader, assign_target, device=device,\n",
        "                 scheduler=scheduler, assign_target_kwargs={\"neg_th\":0.4, \"pos_th\":0.6},\n",
        "                 val_dataloader=test_dataloader)\n",
        "\n",
        "num_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb879d34-5508-4331-b33f-af4446d07306",
      "metadata": {
        "scrolled": true,
        "id": "cb879d34-5508-4331-b33f-af4446d07306"
      },
      "outputs": [],
      "source": [
        "runner.train(num_epochs=num_epochs, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0bb106f-595e-4db6-b0c4-1803a6a5607a",
      "metadata": {
        "id": "d0bb106f-595e-4db6-b0c4-1803a6a5607a"
      },
      "source": [
        "Нарисуем график изменения лосса в процессе обучения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82d68754-52d7-4bbb-8c73-1ab0d71fc1f5",
      "metadata": {
        "id": "82d68754-52d7-4bbb-8c73-1ab0d71fc1f5"
      },
      "outputs": [],
      "source": [
        "runner.plot_loss(row_figsize=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bf4aa10-9aa8-416f-a57e-da9ac8cbabb5",
      "metadata": {
        "id": "6bf4aa10-9aa8-416f-a57e-da9ac8cbabb5"
      },
      "source": [
        "При желании можем сохранить обученную модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f73d507-cb31-4253-bd6b-92765ff9b950",
      "metadata": {
        "id": "3f73d507-cb31-4253-bd6b-92765ff9b950"
      },
      "outputs": [],
      "source": [
        "# torch.save(model, open(\"./detector\", 'wb'))\n",
        "# or\n",
        "# torch.save(model.state_dict(), \"./detector_sd\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6eda1b70-4fbf-4c80-aaf8-ec42dc1bdd5c",
      "metadata": {
        "id": "6eda1b70-4fbf-4c80-aaf8-ec42dc1bdd5c"
      },
      "source": [
        "### Model Predictions\n",
        "\n",
        "Осталось только посмотреть на предсказания и посчитать метрики качества!\n",
        "Начем с примеров предсказаний. Напишем небольшую функцию, которая будет делать предсказание моделью, фильтровать предсказания по confidence score и применять алгоритм NMS также с заданным трешхолдом."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9920d48-2f88-461b-a2ce-ffeb1f8148ba",
      "metadata": {
        "id": "e9920d48-2f88-461b-a2ce-ffeb1f8148ba"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def predict(model, images, device, score_threshold=0.1, nms_threshold=0.5, max_boxes_per_cls=8, return_type='list'):\n",
        "    \"\"\" Предсказание моделью для переданного набора изображений после фильтрации по score_threshold\n",
        "    и применения NMS.\n",
        "\n",
        "    Параметры\n",
        "    --------\n",
        "    images : torch.tensor, содержащий картинки для которых нужно сделать предсказание.\n",
        "    Необходимые преобразования должны быть сделаны ДО. Внутри метода `predict` никаких преобразований\n",
        "    не происходит.\n",
        "    score_threshold : Все предсказания, с (confidence score * cls_probs) < score_threshold будут проигнорированны.\n",
        "    nms_threshold : Предсказания, имеющие пересечение по IoU >= nms_threshold будут считаться одним предсказанием.\n",
        "    max_boxes_per_cls : Максимальное количество ббоксов на изображение для одного класса после фильтрации по `score_threshold`.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    final_predictions : List[dict], где каждый словарь содержащий следующие ключи:\n",
        "        \"boxes\" : координаты ббоксов на i-ом изображении,\n",
        "        \"labels\" : классы внутри ббоксов,\n",
        "        \"scores\" : Confidence scores для ббоксов.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    images = images.to(device)\n",
        "    outputs = model(images)\n",
        "    final_predictions =  _filter_predictions(outputs, score_threshold=score_threshold, nms_threshold=nms_threshold,\n",
        "                                             max_boxes_per_cls=max_boxes_per_cls, return_type=return_type)\n",
        "    return final_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b3bd33e-dea0-4918-9160-278f390dc474",
      "metadata": {
        "id": "7b3bd33e-dea0-4918-9160-278f390dc474"
      },
      "outputs": [],
      "source": [
        "def plot_predictions(images, predictions, figsize=(12, 3)):\n",
        "    \"\"\" Рисуем по 3 предсказания на одной строке. \"\"\"\n",
        "    ncols = min(len(images), 3)\n",
        "    for ix in range(0, len(images), ncols):\n",
        "        _, axes = plt.subplots(1, ncols, figsize=figsize, tight_layout=True)\n",
        "        for i, (ax, img) in enumerate(zip(axes, images[ix: ix+ncols])):\n",
        "            img = img.cpu().permute(1, 2, 0).numpy()\n",
        "            img = img * np.array(std).reshape(1, 1, -1) + np.array(mean).reshape(1, 1, -1)\n",
        "            img = np.ascontiguousarray((img * 255).astype(np.uint8))\n",
        "            preds = predictions[ix + i]\n",
        "            for bbox, label, score in zip(preds[\"boxes\"], preds[\"labels\"], preds[\"scores\"]):\n",
        "                color = class_to_color[label+1]\n",
        "                label = class_to_name[label+1]\n",
        "                img = add_bbox(img, bbox, label=f\"Class {label}: {score:.2f}\", color=color)\n",
        "            ax.imshow(img)\n",
        "            ax.set_xticks([])\n",
        "            ax.set_yticks([])\n",
        "        plt.show()\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4714b344-f9f2-4bdf-96ba-42b3d04bd025",
      "metadata": {
        "id": "4714b344-f9f2-4bdf-96ba-42b3d04bd025"
      },
      "outputs": [],
      "source": [
        "test_iter = iter(test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33df4c1f-5d7e-4348-afbd-ef4d69eb0368",
      "metadata": {
        "id": "33df4c1f-5d7e-4348-afbd-ef4d69eb0368"
      },
      "outputs": [],
      "source": [
        "score_threshold = 0.1\n",
        "nms_threshold = 0.4\n",
        "\n",
        "images, _ = next(test_iter)\n",
        "preds = predict(model, images, device=device, score_threshold=score_threshold, nms_threshold=nms_threshold)\n",
        "plot_predictions(images, preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db586c6a-1276-4901-ad84-0bfb2f01d2ed",
      "metadata": {
        "id": "db586c6a-1276-4901-ad84-0bfb2f01d2ed"
      },
      "source": [
        "### Quality assessment\n",
        "\n",
        "Посчитаем качество итоговой модели (mAP) используя COCO API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb5b4f6f-79ee-4ffa-81a5-10f1da40bf1c",
      "metadata": {
        "id": "bb5b4f6f-79ee-4ffa-81a5-10f1da40bf1c"
      },
      "outputs": [],
      "source": [
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "\n",
        "@torch.no_grad()\n",
        "def compute_coco_map(model, dataloader, device, score_threshold=0.01, nms_threshold=0.5, num_classes=4):\n",
        "    \"\"\" Считаем mAP модели на данных из `dataloader`. \"\"\"\n",
        "    model.eval()\n",
        "    ann_id = 1\n",
        "    all_detections = []\n",
        "    all_gt_annotations = []\n",
        "    images_info = []\n",
        "\n",
        "    for images, targets in tqdm(dataloader, desc=\"Dataset Evaluation\"):\n",
        "        # Делаем предсказание для всех картинок в батче\n",
        "        predictions = predict(model, images, device, score_threshold, nms_threshold)\n",
        "        # Сохраняем изначальные картинки, предсказания и таргет в формате COCO\n",
        "        for i in range(images.shape[0]):\n",
        "            image_id = targets[i][\"image_id\"]\n",
        "            images_info.append({\n",
        "                \"id\": image_id,\n",
        "                \"width\": images[i].shape[1],\n",
        "                \"height\": images[i].shape[2]\n",
        "            })\n",
        "\n",
        "            # Сохраняем предсказания модели в формате COCO\n",
        "            img_pred = predictions[i]\n",
        "            for box, cls, sc in zip(img_pred[\"boxes\"], img_pred[\"labels\"], img_pred[\"scores\"]):\n",
        "                detection = {\n",
        "                    \"image_id\": image_id,\n",
        "                    \"category_id\": cls + 1,  # Классы в COCO начинаются с 1\n",
        "                    \"bbox\": list(box),  # Бокс в COCO формате [x, y, w, h]\n",
        "                    \"score\": sc\n",
        "                }\n",
        "                all_detections.append(detection)\n",
        "\n",
        "            # Сохраняем таргет в формате COCO\n",
        "            gt_boxes = targets[i]['boxes'].cpu().numpy().tolist()\n",
        "            gt_labels = targets[i]['labels'].cpu().numpy().tolist()\n",
        "            for box, label in zip(gt_boxes, gt_labels):\n",
        "                gt_annotation = {\n",
        "                    \"id\": ann_id,\n",
        "                    \"image_id\": image_id,\n",
        "                    \"category_id\": label + 1,\n",
        "                    \"bbox\": box,\n",
        "                    \"area\": box[2] * box[3],\n",
        "                    \"iscrowd\": 0\n",
        "                }\n",
        "                all_gt_annotations.append(gt_annotation)\n",
        "                ann_id += 1\n",
        "\n",
        "    coco_gt_dict = {\n",
        "        \"images\": images_info,\n",
        "        \"annotations\": all_gt_annotations,\n",
        "        \"categories\": [{\"id\": i+1, \"name\": f\"class_{i}\"} for i in range(model.num_classes)]\n",
        "    }\n",
        "\n",
        "    coco_gt = COCO()\n",
        "    coco_gt.dataset = coco_gt_dict\n",
        "    coco_gt.createIndex()\n",
        "\n",
        "    coco_dt = coco_gt.loadRes(all_detections)\n",
        "\n",
        "    coco_eval = COCOeval(coco_gt, coco_dt, iouType='bbox')\n",
        "    coco_eval.evaluate()\n",
        "    coco_eval.accumulate()\n",
        "    coco_eval.summarize()\n",
        "\n",
        "    overall_mAP = coco_eval.stats[0]\n",
        "    print(f\"Validation mAP: {overall_mAP:.4f}\\n\\n\")\n",
        "\n",
        "    class_maps = {}\n",
        "    for cat_id in range(1, num_classes + 1):\n",
        "        class_name = class_to_name[cat_id]\n",
        "        print(f\"\\nmAP for class {class_name}\")\n",
        "        print(\"-\" * 50)\n",
        "        coco_eval_cat = COCOeval(coco_gt, coco_dt, iouType='bbox')\n",
        "        coco_eval_cat.params.catIds = [cat_id]\n",
        "        coco_eval_cat.params.imgIds = coco_gt.getImgIds(catIds=[cat_id])\n",
        "        coco_eval_cat.evaluate()\n",
        "        coco_eval_cat.accumulate()\n",
        "        coco_eval_cat.summarize();\n",
        "        ap = coco_eval_cat.stats[0]\n",
        "        class_maps[cat_id] = ap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f355172-d752-4588-b0fb-4f34587ebd8c",
      "metadata": {
        "id": "5f355172-d752-4588-b0fb-4f34587ebd8c"
      },
      "outputs": [],
      "source": [
        "score_threshold = 0.1\n",
        "nms_threshold = 0.5\n",
        "compute_coco_map(model, test_dataloader, device=device, score_threshold=score_threshold, nms_threshold=nms_threshold)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06b7304a-a517-461e-bf63-fa5b68fd13d9",
      "metadata": {
        "id": "06b7304a-a517-461e-bf63-fa5b68fd13d9"
      },
      "source": [
        "### Заключение\n",
        "Сегодня мы с вами написали наш первый детектор! Помимо самой модели мы смогли сделать следующее:\n",
        "1. Реализовали весь процесс работы с якорями и ббоксами, а именно:\n",
        "   * Создание якорей,\n",
        "   * Сопоставление якорей с GT,\n",
        "   * Вычисление лосса как разницы между предсказанными и GT смещениями,\n",
        "   * Предсказание итоговых ббоксов,\n",
        "2. Реализовали метод обучения модели,\n",
        "3. Написали метод для валидации нашей модели и измерения качества (mAP)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}